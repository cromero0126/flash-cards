[
  {
    "question": "The process of visiting each node in a tree exactly once is called __________",
    "choices": [
      "Tree Traversal",
      "Tree Sorting",
      "Tree Insertion",
      "Tree Deletion"
    ],
    "correctIndex": 0,
    "explanation": "Tree traversal is a systematic way to visit all nodes in a tree data structure. Common methods like in-order, pre-order, and post-order ensure that each node is processed precisely once, which is fundamental for many tree-based operations."
  },
  {
    "question": "What is the best-case time complexity of the binary search algorithm?",
    "choices": [
      "O(1)",
      "O(log n)",
      "O(n)",
      "O(n log n)"
    ],
    "correctIndex": 0,
    "explanation": "In its best-case scenario, binary search finds the target element on the very first comparison, specifically if the target is located at the middle element of the array. This direct hit results in a constant time complexity, regardless of the array's size."
  },
  {
    "question": "If an algorithm has two nested loops, each running from 1 to n, what is its time complexity?",
    "choices": [
      "O(n²)",
      "O(n)",
      "O(log n)",
      "O(n log n)"
    ],
    "correctIndex": 0,
    "explanation": "When you have two nested loops, and each loop iterates 'n' times, the total number of operations grows proportionally to n multiplied by n. This quadratic relationship is precisely what O(n²) represents in Big-O notation, indicating a significantly increasing execution time as 'n' gets larger."
  },
  {
    "question": "The primary goal of analyzing time complexity is to:",
    "choices": [
      "Optimize algorithm execution time",
      "Determine the required memory space",
      "Measure the speed of a program",
      "Count the number of recursive calls"
    ],
    "correctIndex": 0,
    "explanation": "Analyzing time complexity helps predict how an algorithm's running time scales with input size, allowing us to choose or design algorithms that perform efficiently, especially for large datasets. This prediction is crucial for optimizing performance rather than just measuring raw speed."
  },
  {
    "question": "When using Big-O notation, what is typically ignored?",
    "choices": [
      "The constant factors and lower-order terms",
      "The input size",
      "The worst-case scenario",
      "The leading coefficients"
    ],
    "correctIndex": 0,
    "explanation": "Big-O notation focuses on the asymptotic behavior of an algorithm, describing its growth rate as input size approaches infinity. Therefore, constant factors and less significant lower-order terms are disregarded as their impact becomes negligible for large inputs, emphasizing the dominant term."
  },
  {
    "question": "Which of the following data structures has an average-case time complexity of O(1) for accessing an element?",
    "choices": [
      "Hash Table",
      "Linked List",
      "Binary Search Tree",
      "Stack"
    ],
    "correctIndex": 0,
    "explanation": "Hash tables, on average, offer constant-time O(1) access to elements. This efficiency is achieved by directly computing an element's location using a hash function, assuming minimal collisions. In contrast, other structures like linked lists or binary search trees typically require more time for access."
  },
  {
    "question": "What is the time complexity of finding an element in an unsorted array using a linear search?",
    "choices": [
      "O(n)",
      "O(log n)",
      "O(n²)",
      "O(1)"
    ],
    "correctIndex": 0,
    "explanation": "In an unsorted array, a linear search must potentially check every element in the worst case to find the target or determine its absence. This means the number of operations grows linearly with the size of the array, 'n', hence O(n) complexity."
  },
  {
    "question": "Which of the following best describes an Abstract Data Type (ADT)?",
    "choices": [
      "A mathematical model with defined operations but no specific implementation",
      "A concrete implementation of a data structure",
      "A programming language feature",
      "A built-in data structure in programming"
    ],
    "correctIndex": 0,
    "explanation": "An ADT is a high-level conceptual model that specifies a set of data values and operations that can be performed on them, without detailing how these operations are implemented. It focuses on 'what' can be done rather than 'how' it's done, providing a blueprint for data structures."
  },
  {
    "question": "The space complexity of an algorithm depends on the input size and the __________ space required during execution.",
    "choices": [
      "Auxiliary",
      "Primary",
      "Temporary",
      "Recursion"
    ],
    "correctIndex": 0,
    "explanation": "Space complexity measures the total memory an algorithm uses, which includes the space taken by the input data and any additional space the algorithm requires for its computations, known as auxiliary space. This auxiliary space is temporary and used for variables, data structures, or recursive call stacks."
  },
  {
    "question": "What is the advantage of a linked list over an array?",
    "choices": [
      "Dynamic memory allocation",
      "Faster access to elements",
      "Fixed size allocation",
      "Requires less memory"
    ],
    "correctIndex": 0,
    "explanation": "Linked lists excel in dynamic memory allocation, allowing them to grow or shrink in size during runtime without needing contiguous memory blocks. This flexibility contrasts with arrays, which typically require a fixed size declared at compile time or initial allocation."
  },
  {
    "question": "If an algorithm runs in O(n log n) time, which of the following sorting algorithms could it be?",
    "choices": [
      "Average case Quick Sort",
      "Bubble Sort",
      "Insertion Sort",
      "Selection Sort"
    ],
    "correctIndex": 0,
    "explanation": "Average case Quick Sort, along with Merge Sort and Heap Sort, exhibits an O(n log n) time complexity, which is considered highly efficient for sorting large datasets. This logarithmic factor arises from the divide-and-conquer strategy employed by these algorithms."
  },
  {
    "question": "If an algorithm requires constant space, what is its space complexity?",
    "choices": [
      "O(1)",
      "O(n)",
      "O(n log n)",
      "O(n²)"
    ],
    "correctIndex": 0,
    "explanation": "Constant space complexity, denoted as O(1), signifies that the amount of memory an algorithm uses remains fixed regardless of the input size. This implies that the algorithm does not require additional memory that scales with the input."
  },
  {
    "question": "The Big-O notation represents the best-case performance of an algorithm.",
    "choices": [
      "False",
      "True"
    ],
    "correctIndex": 0,
    "explanation": "Big-O notation primarily describes the upper bound or worst-case time complexity of an algorithm, indicating how its running time grows at most. While other notations like Omega (Ω) and Theta (Θ) describe best-case and average-case scenarios, Big-O is specifically for the worst-case."
  },
  {
    "question": "In a __________ sort algorithm, the list is divided into smaller sublists that are sorted and then merged back together.",
    "choices": [
      "Merge Sort",
      "Insertion Sort",
      "Heap Sort",
      "Selection Sort"
    ],
    "correctIndex": 0,
    "explanation": "Merge Sort is a classic divide-and-conquer algorithm. It recursively breaks down a list into individual elements, then repeatedly merges these sorted sublists to produce new sorted sublists until there is only one sorted list remaining."
  },
  {
    "question": "What does it mean if algorithm X is asymptotically more efficient than algorithm Y?",
    "choices": [
      "X will always be a better choice for large inputs",
      "X will always be a better choice for small inputs",
      "Y will always be a better choice for small inputs",
      "X will always be a better choice for all inputs"
    ],
    "correctIndex": 0,
    "explanation": "Asymptotic efficiency refers to the performance of an algorithm as the input size approaches infinity. If algorithm X is asymptotically more efficient than algorithm Y, it means X will eventually outperform Y for sufficiently large inputs, even if Y might be faster for small inputs due to constant factors."
  },
  {
    "question": "Which of the following is a key advantage of a stack compared to a queue?",
    "choices": [
      "Supports Last In, First Out (LIFO) access, useful for function calls and backtracking",
      "Provides faster searching of elements",
      "Allows access to elements in FIFO order",
      "Requires less memory for storing elements"
    ],
    "correctIndex": 0,
    "explanation": "Stacks operate on a Last-In, First-Out (LIFO) principle, meaning the last element added is the first one removed. This makes them ideal for managing function call hierarchies in programming (the call stack) and implementing algorithms that involve backtracking, such as depth-first search."
  },
  {
    "question": "Which Big-O notation represents the worst-case time complexity of a balanced binary search tree (BST) search operation?",
    "choices": [
      "O(log n)",
      "O(n)",
      "O(n²)",
      "O(1)"
    ],
    "correctIndex": 0,
    "explanation": "In a balanced BST, each comparison effectively halves the search space, similar to binary search in a sorted array. This logarithmic reduction in search space leads to a worst-case time complexity of O(log n), making BSTs highly efficient for search, insertion, and deletion operations."
  },
  {
    "question": "Which of the following best describes space complexity in data structures?",
    "choices": [
      "The total amount of memory required by an algorithm, including input size and auxiliary space",
      "The number of steps an algorithm takes to complete execution",
      "The amount of time required for an algorithm to execute based on input size",
      "The total number of recursive calls made during execution"
    ],
    "correctIndex": 0,
    "explanation": "Space complexity quantifies the total memory an algorithm uses during its execution, encompassing both the memory consumed by the input data itself and any additional temporary memory, or auxiliary space, the algorithm needs to complete its task. This measure is crucial for understanding an algorithm's resource footprint."
  },
  {
    "question": "In an unsorted array of size n, what is the worst-case time complexity of searching for an element?",
    "choices": [
      "O(n)",
      "O(log n)",
      "O(1)",
      "O(n log n)"
    ],
    "correctIndex": 0,
    "explanation": "In the worst-case scenario for an unsorted array, a linear search algorithm must iterate through every single element to find a specific item or confirm its absence. Consequently, the time taken directly scales with the number of elements 'n', resulting in O(n) complexity."
  },
  {
    "question": "What is the time complexity of accessing an element in an array by index?",
    "choices": [
      "O(1)",
      "O(n)",
      "O(log n)",
      "O(n log n)"
    ],
    "correctIndex": 0,
    "explanation": "Accessing an element in an array by its index is a constant-time operation, denoted as O(1). This is because arrays store elements in contiguous memory locations, allowing direct calculation of any element's address based on its index, regardless of the array's size."
  },
  {
    "question": "Which sorting algorithm has an average-case time complexity of O(n²)?",
    "choices": [
      "Bubble Sort",
      "Quick Sort",
      "Merge Sort",
      "Heap Sort"
    ],
    "correctIndex": 0,
    "explanation": "Bubble Sort is known for its simplicity but is inefficient for large datasets, with an average-case time complexity of O(n²). This quadratic complexity arises from its process of repeatedly stepping through the list, comparing adjacent elements, and swapping them if they are in the wrong order."
  },
  {
    "question": "A graph that has no cycles is called a __________ graph.",
    "choices": [
      "Acyclic",
      "Directed",
      "Cyclic",
      "Weighted"
    ],
    "correctIndex": 0,
    "explanation": "An acyclic graph is one that contains no cycles, meaning there is no path that starts and ends at the same vertex. A common example is a tree, which is a specific type of undirected acyclic graph, crucial in many algorithms for representing hierarchies or dependencies without redundant connections."
  },
  {
    "question": "The space complexity of a recursive function is affected by the call stack.",
    "choices": [
      "True",
      "False"
    ],
    "correctIndex": 0,
    "explanation": "True. Each recursive call adds a new frame to the call stack, storing local variables and return addresses. In the worst case, for deeply recursive functions, the space consumed by the call stack can grow linearly with the depth of recursion, impacting the overall space complexity."
  },
  {
    "question": "If an algorithm’s time complexity is O(1), what does it imply?",
    "choices": [
      "The execution time is constant, regardless of input size",
      "The execution time increases linearly with input size",
      "The execution time grows exponentially",
      "The execution time is logarithmic"
    ],
    "correctIndex": 0,
    "explanation": "An algorithm with O(1) time complexity means its execution time remains constant, irrespective of the input size. This indicates that the algorithm performs a fixed number of operations, making it incredibly efficient for any scale of data."
  },
  {
    "question": "O(n³) represents a more efficient algorithm than O(n log n) for large input sizes.",
    "choices": [
      "False",
      "True"
    ],
    "correctIndex": 0,
    "explanation": "False. For large input sizes, O(n log n) is significantly more efficient than O(n³). The logarithmic factor in O(n log n) grows much slower than a cubic factor, meaning algorithms with O(n log n) complexity will outperform those with O(n³) as 'n' increases."
  },
  {
    "question": "The time complexity of binary search in a sorted array is ___.",
    "choices": [
      "O(log n)",
      "O(n)",
      "O(n²)",
      "O(1)"
    ],
    "correctIndex": 0,
    "explanation": "Binary search operates by repeatedly dividing the search interval in half. This halving of the problem size with each comparison leads to a logarithmic time complexity, O(log n), making it very efficient for searching in large sorted datasets."
  },
  {
    "question": "Which data structure follows the Last In, First Out (LIFO) principle?",
    "choices": [
      "Stack",
      "Queue",
      "Linked List",
      "Tree"
    ],
    "correctIndex": 0,
    "explanation": "A stack adheres to the Last In, First Out (LIFO) principle, where the last element added to the stack is the first one to be removed. Think of a stack of plates: you can only remove the top plate, which was the last one placed there."
  },
  {
    "question": "What is the time complexity of inserting an element at the beginning of a linked list?",
    "choices": [
      "O(1)",
      "O(n)",
      "O(log n)",
      "O(n log n)"
    ],
    "correctIndex": 0,
    "explanation": "Inserting an element at the beginning of a singly linked list is an O(1) operation because it only requires updating a few pointers (the new node's next pointer and the head pointer). The operation does not depend on the number of elements already in the list."
  },
  {
    "question": "The Big-O notation describes the __________ limit of an algorithm’s growth rate.",
    "choices": [
      "Worst-case",
      "Average-case",
      "Best-case",
      "Expected-case"
    ],
    "correctIndex": 0,
    "explanation": "Big-O notation formally expresses the upper bound on the growth rate of an algorithm's runtime or space requirements as the input size increases. It specifically focuses on the worst-case scenario, providing a guarantee of maximum resources an algorithm might consume."
  },
  {
    "question": "What is the main characteristic of a hash function in a hash table?",
    "choices": [
      "It transforms a key into an index in constant time",
      "It ensures a unique value for each key",
      "It maps keys to values randomly",
      "It performs a sequential search"
    ],
    "correctIndex": 0,
    "explanation": "The primary role of a hash function is to deterministically convert a given key into an array index where the corresponding value can be stored or retrieved. Ideally, this computation should be performed in constant time, O(1), enabling very fast average-case access to data."
  },
    {
    "question": "In a priority queue, the element with the lowest priority is always removed first.",
    "choices": [
      "False",
      "True"
    ],
    "correctIndex": 0,
    "explanation": "False. In a priority queue, elements are removed based on their priority, not necessarily the lowest. By convention, the element with the *highest* priority is removed first, though implementations can vary (e.g., min-priority queue removes the lowest priority)."
  },
  {
    "question": "In recursion, the condition that stops further recursive calls is called the _______.",
    "choices": [
      "Base case",
      "Recursive step",
      "Exit point",
      "Function call"
    ],
    "correctIndex": 0,
    "explanation": "The base case in recursion is the condition under which the function returns a value without making any further recursive calls. It's essential to prevent infinite recursion and ensure the function eventually terminates."
  },
  {
    "question": "What is the main advantage of a circular queue over a linear queue?",
    "choices": [
      "It efficiently utilizes memory by reusing empty spaces",
      "It allows infinite insertions",
      "It eliminates the need for pointers",
      "It works faster than all other data structures"
    ],
    "correctIndex": 0,
    "explanation": "A circular queue efficiently utilizes memory by allowing the reuse of empty spaces at the beginning of the queue once elements have been dequeued. In a linear queue, once the rear reaches the end of the array, no more elements can be inserted even if there are empty slots at the front, leading to wasted space."
  },
  {
    "question": "Which operation is used to remove an element from a queue?",
    "choices": [
      "Dequeue",
      "Push",
      "Pop",
      "Insert"
    ],
    "correctIndex": 0,
    "explanation": "Dequeue is the standard operation to remove an element from the front of a queue, following the First-In, First-Out (FIFO) principle. Push and Pop are operations associated with stacks, while Insert is a general term for adding elements to various data structures."
  },
  {
    "question": "Which data structure operates on a First In, First Out (FIFO) principle?",
    "choices": [
      "Queue",
      "Stack",
      "Tree",
      "Graph"
    ],
    "correctIndex": 0,
    "explanation": "A Queue is a linear data structure that follows the FIFO principle, meaning the first element added to the queue is the first one to be removed. This is analogous to a line of people waiting for a service."
  },
  {
    "question": "If an element is removed from an empty queue, a condition known as _______ occurs.",
    "choices": [
      "Underflow",
      "Overflow",
      "Runtime Error",
      "Stack Crash"
    ],
    "correctIndex": 0,
    "explanation": "Underflow occurs when an attempt is made to remove an element from a data structure that is already empty. For a queue, this means performing a dequeue operation when there are no elements in the queue."
  },
  {
    "question": "If front == rear in a circular queue and no elements exist, what condition is this?",
    "choices": [
      "Empty queue",
      "Full queue",
      "Overflow",
      "Sorted queue"
    ],
    "correctIndex": 0,
    "explanation": "In a common implementation of a circular queue, when the `front` and `rear` pointers are equal, and no elements have been added (or all have been removed), it signifies an empty queue. To distinguish from a full queue (where front also equals rear but with elements present), an additional flag or a size counter is typically used."
  },
  {
    "question": "In a circular queue, if rear == front - 1, the queue is full.",
    "choices": [
      "True",
      "False"
    ],
    "correctIndex": 0,
    "explanation": "True. In a common implementation of a circular queue using an array, one spot is often left empty to differentiate between a full queue and an empty queue (where front == rear). Thus, if `rear` is one position behind `front` (modulo array size), it indicates that the queue is full."
  },
  {
    "question": "What happens when a circular queue becomes full?",
    "choices": [
      "No more elements can be inserted until space is freed",
      "The queue resets automatically",
      "The queue crashes",
      "New elements overwrite existing ones"
    ],
    "correctIndex": 0,
    "explanation": "When a circular queue becomes full, it means all allocated slots are occupied (or all but one, depending on implementation). Therefore, no new elements can be inserted (enqueued) until existing elements are removed (dequeued) to free up space, preventing overflow."
  },
  {
    "question": "When evaluating a postfix expression, how are operands processed?",
    "choices": [
      "Pushed onto the stack until an operator is encountered",
      "Stored in an array",
      "Arranged in ascending order",
      "Appended to a linked list"
    ],
    "correctIndex": 0,
    "explanation": "When evaluating a postfix expression, operands are encountered first. According to the algorithm, these operands are immediately pushed onto a stack. When an operator is encountered, the necessary number of operands are popped from the stack, the operation is performed, and the result is pushed back onto the stack."
  },
  {
    "question": "In the expression (5 + 3) * 2, which operation is performed first according to infix notation?",
    "choices": [
      "Addition",
      "Multiplication",
      "Subtraction",
      "Modulus"
    ],
    "correctIndex": 0,
    "explanation": "According to the rules of operator precedence in infix notation (PEMDAS/BODMAS), operations within parentheses are always performed first. Therefore, the addition (5 + 3) is evaluated before the multiplication."
  },
  {
    "question": "When converting an infix expression to a postfix expression, the _______ data structure is used.",
    "choices": [
      "Stack",
      "Queue",
      "Array",
      "Tree"
    ],
    "correctIndex": 0,
    "explanation": "A stack is the primary data structure used in the Shunting-yard algorithm for converting infix expressions to postfix (or prefix) expressions. It temporarily holds operators and parentheses to manage their precedence and order during the conversion process."
  },
  {
    "question": "Which of the following data structures is used to implement a priority queue?",
    "choices": [
      "Heap",
      "Stack",
      "Linked List",
      "Graph"
    ],
    "correctIndex": 0,
    "explanation": "A Heap (specifically a min-heap or max-heap) is the most common and efficient data structure used to implement a priority queue. It allows for efficient retrieval of the highest (or lowest) priority element and efficient insertion/deletion, maintaining the heap property."
  },
  {
    "question": "In a priority queue, elements are dequeued based on their priority rather than their order of arrival.",
    "choices": [
      "True",
      "False"
    ],
    "correctIndex": 0,
    "explanation": "True. This is the defining characteristic of a priority queue. Unlike a standard queue (FIFO), elements are not necessarily removed in the order they were inserted. Instead, the element with the highest (or lowest) priority, as defined by the queue, is always the next one to be dequeued."
  },
  {
    "question": "Which of the following algorithms commonly utilizes a stack data structure?",
    "choices": [
      "Depth-first search (DFS)",
      "Level-order traversal",
      "Hashing",
      "Dynamic programming"
    ],
    "correctIndex": 0,
    "explanation": "Depth-first search (DFS) algorithm for traversing trees or graphs typically uses a stack (either explicitly or implicitly through recursion's call stack) to keep track of nodes to visit. When a node is visited, its unvisited neighbors are pushed onto the stack, and the algorithm proceeds deeper before backtracking."
  },
  {
    "question": "The front of a circular queue is used for _______.",
    "choices": [
      "Removing elements",
      "Inserting elements",
      "Sorting elements",
      "Searching elements"
    ],
    "correctIndex": 0,
    "explanation": "In both linear and circular queues, the 'front' pointer (or index) is consistently used to manage the removal of elements, adhering to the First-In, First-Out (FIFO) principle."
  },
  {
    "question": "What happens when a stack is empty, and a pop operation is performed?",
    "choices": [
      "Underflow occurs",
      "Overflow occurs",
      "The last element is retrieved",
      "The operation executes successfully"
    ],
    "correctIndex": 0,
    "explanation": "Performing a pop operation on an empty stack results in an 'underflow' condition. This indicates an error because there are no elements to remove from the stack."
  },
  {
    "question": "Recursive functions use more memory than iterative functions because each recursive call is stored in the stack.",
    "choices": [
      "True",
      "False"
    ],
    "correctIndex": 0,
    "explanation": "True. Each time a recursive function calls itself, a new stack frame is created on the call stack to store its local variables, parameters, and return address. This repeated allocation can lead to significantly more memory consumption compared to an iterative solution, especially for deep recursion."
  },
  {
    "question": "For which operation is the front of a queue used?",
    "choices": [
      "Removing elements",
      "Adding elements",
      "Sorting elements",
      "Searching elements"
    ],
    "correctIndex": 0,
    "explanation": "The front of a queue is where elements are removed. This aligns with the First-In, First-Out (FIFO) principle of a queue, where the element that has been in the queue the longest is the first to be dequeued."
  },
  {
    "question": "What are the primary operations performed on a stack?",
    "choices": [
      "Push and Pop",
      "Enqueue and Dequeue",
      "Insert and Remove",
      "Append and Delete"
    ],
    "correctIndex": 0,
    "explanation": "The two fundamental operations on a stack are 'Push' (to add an element to the top) and 'Pop' (to remove the top element). Stacks adhere to the Last-In, First-Out (LIFO) principle."
  },
  {
    "question": "What is the main function of the \"push\" operation in a stack?",
    "choices": [
      "Adds an element to the top of the stack",
      "Removes an element from the top of the stack",
      "Retrieves the bottom element",
      "Sorts the stack"
    ],
    "correctIndex": 0,
    "explanation": "The 'push' operation is used to add a new element to the top of a stack. This adheres to the Last-In, First-Out (LIFO) principle, where the most recently added element is the first one accessible."
  },
  {
    "question": "In a circular queue of size 5, if the rear is at position 4 and a new element is inserted, where will the rear move?",
    "choices": [
      "0",
      "5",
      "3",
      "1"
    ],
    "correctIndex": 0,
    "explanation": "In a circular queue implementation using an array, when the `rear` pointer reaches the end of the physical array (index `size - 1`), and there is still space available at the beginning of the array, it 'wraps around' to index 0. So, for a size 5 queue (indices 0-4), if rear is at 4, the next position would be 0 (assuming space is available and no overflow)."
  },
  {
    "question": "A circular queue can be efficiently implemented using _______.",
    "choices": [
      "Arrays or linked lists",
      "Stacks",
      "Trees",
      "Hash tables"
    ],
    "correctIndex": 0,
    "explanation": "A circular queue can be efficiently implemented using either an array (by managing front and rear pointers with modulo arithmetic to wrap around) or a circular linked list (where the last node points back to the first). Both methods allow for constant-time enqueue and dequeue operations."
  },
  {
    "question": "Which data structure operates based on the principle of \"Last In, First Out (LIFO)\"?",
    "choices": [
      "Stack",
      "Queue",
      "Linked List",
      "Heap"
    ],
    "correctIndex": 0,
    "explanation": "A Stack is a linear data structure that follows the LIFO principle. This means the last element added to the stack is the first one to be removed, similar to a stack of plates."
  },
  {
    "question": "The two fundamental operations of a queue are _______ and _______.",
    "choices": [
      "Enqueue, Dequeue",
      "Push, Pop",
      "Insert, Delete",
      "Add, Remove"
    ],
    "correctIndex": 0,
    "explanation": "'Enqueue' is the operation to add an element to the rear of a queue, and 'Dequeue' is the operation to remove an element from the front of a queue. These are the specific terms for the core operations that maintain the First-In, First-Out (FIFO) behavior."
  },
  {
    "question": "What data structure is used for evaluating postfix expressions?",
    "choices": [
      "Stack",
      "Queue",
      "Linked List",
      "Tree"
    ],
    "correctIndex": 0,
    "explanation": "A stack is crucial for evaluating postfix expressions. Operands are pushed onto the stack, and when an operator is encountered, the necessary number of operands are popped, the operation is performed, and the result is pushed back onto the stack. This LIFO behavior is ideal for managing the order of operations."
  },
  {
    "question": "What happens when a recursive function keeps calling itself indefinitely without a base case?",
    "choices": [
      "Stack overflow",
      "Stack underflow",
      "Function termination",
      "Compilation error"
    ],
    "correctIndex": 0,
    "explanation": "If a recursive function lacks a proper base case or the base case is never reached, it will continue to call itself indefinitely. Each call consumes memory on the call stack, eventually leading to a 'stack overflow' error when the stack runs out of available memory."
  },
  {
    "question": "Which of the following problems is commonly solved using recursion?",
    "choices": [
      "Tower of Hanoi",
      "Sorting using Bubble Sort",
      "Searching in an unsorted array",
      "Hash table lookup"
    ],
    "correctIndex": 0,
    "explanation": "The Tower of Hanoi is a classic mathematical puzzle that is most elegantly and commonly solved using a recursive algorithm. Its self-similar nature naturally lends itself to a recursive solution."
  },
  {
    "question": "What is the main reason recursion is implemented using a stack?",
    "choices": [
      "To keep track of function calls and local variables",
      "To make code execution faster",
      "To reduce the number of function calls",
      "To store global variables"
    ],
    "correctIndex": 0,
    "explanation": "The underlying mechanism for recursion in most programming languages is the call stack. Each time a recursive function is called, a new stack frame is pushed onto the call stack to store the function's parameters, local variables, and the return address. This allows the program to correctly unwind and return from nested calls."
  },
  {
    "question": "In a priority queue, elements are dequeued based on their _______.",
    "choices": [
      "Priority level",
      "Order of arrival",
      "Random selection",
      "Position in an array"
    ],
    "correctIndex": 0,
    "explanation": "The defining characteristic of a priority queue is that elements are removed (dequeued) not based on their insertion order (FIFO) but rather based on their assigned priority. The element with the highest (or lowest, depending on the implementation) priority is always processed first."
  },
   {
    "question": "Which operation is most time-consuming in a singly linked list?",
    "choices": [
      "Deleting the last node",
      "Inserting at the head",
      "Accessing the first node",
      "Traversing from head to tail"
    ],
    "correctIndex": 0,
    "explanation": "Deleting the last node in a singly linked list (without a tail pointer) requires traversing the entire list from the head to find the second-to-last node, whose pointer then needs to be updated to NULL. This makes it an O(N) operation, which is typically the most time-consuming compared to O(1) operations like inserting/accessing the head or O(N) for general traversal."
  },
  {
    "question": "If a node is deleted from a singly linked list, what must be updated?",
    "choices": [
      "The previous node’s pointer",
      "The next node’s pointer",
      "The last node’s pointer",
      "No updates are required"
    ],
    "correctIndex": 0,
    "explanation": "When a node is deleted from a singly linked list, the 'next' pointer of the *previous* node must be updated to bypass the deleted node and point to the node that *was* after the deleted node. This effectively removes the deleted node from the list's sequence."
  },
  {
    "question": "In a singly linked list, deleting a node requires modifying the ______ of the previous node.",
    "choices": [
      "Pointer",
      "Data",
      "Value",
      "Position"
    ],
    "correctIndex": 0,
    "explanation": "To delete a node in a singly linked list, you need to change the 'next' pointer of the node *preceding* the one being deleted. This pointer should then point to the node that the deleted node was originally pointing to, effectively unlinking the node from the list."
  },
  {
    "question": "What is the primary advantage of a doubly linked list compared to a singly linked list?",
    "choices": [
      "Allows traversal in both directions",
      "Searching is easy",
      "Uses less memory",
      "Elements are stored in sorted order"
    ],
    "correctIndex": 0,
    "explanation": "The main advantage of a doubly linked list is that each node contains pointers to both the next and the previous nodes. This allows for efficient traversal in both forward and backward directions, which is not possible in a singly linked list without re-traversing from the head."
  },
  {
    "question": "If an array is declared as int arr[10];, how many elements can it store?",
    "choices": [
      "10",
      "9",
      "11",
      "20"
    ],
    "correctIndex": 0,
    "explanation": "When an array is declared as `int arr[10];`, it allocates space for 10 integer elements. Array indices typically run from 0 to `size - 1`, so in this case, `arr[0]` to `arr[9]`."
  },
  {
    "question": "In an array, elements are stored in ______ memory locations.",
    "choices": [
      "Contiguous",
      "Random",
      "Non-contiguous",
      "Fragmented"
    ],
    "correctIndex": 0,
    "explanation": "Arrays store their elements in contiguous (adjacent) memory locations. This characteristic is what enables efficient random access using an index, as the memory address of any element can be calculated directly from the base address and the element's size."
  },
  {
    "question": "What happens when a node is deleted from a singly linked list?",
    "choices": [
      "The previous node’s pointer is updated to skip the deleted node",
      "All elements shift left",
      "The entire list is reallocated",
      "The node is marked but not removed"
    ],
    "correctIndex": 0,
    "explanation": "When a node is deleted from a singly linked list, the core operation involves updating the 'next' pointer of the node that *precedes* the deleted node. This pointer is redirected to point to the node that *follows* the deleted node, effectively removing the deleted node from the sequence."
  },
  {
    "question": "What is the time complexity of traversing a singly linked list with N nodes?",
    "choices": [
      "O(N)",
      "O(1)",
      "O(log N)",
      "O(N²)"
    ],
    "correctIndex": 0,
    "explanation": "Traversing a singly linked list requires visiting each node sequentially from the beginning to the end. Therefore, in the worst case, if there are N nodes, you need to perform N operations (visits), leading to a time complexity of O(N)."
  },
  {
    "question": "What is the time complexity of searching for an element in an unsorted singly linked list?",
    "choices": [
      "O(n)",
      "O(1)",
      "O(log n)",
      "O(n²)"
    ],
    "correctIndex": 0,
    "explanation": "To search for an element in an unsorted singly linked list, you may have to traverse the entire list from the beginning until the element is found or the end of the list is reached. In the worst-case scenario (element not found or at the end), this requires visiting all 'n' nodes, resulting in a time complexity of O(n)."
  },
  {
    "question": "How many pointers are there in a node of a doubly linked list?",
    "choices": [
      "Two",
      "One",
      "Three",
      "Zero"
    ],
    "correctIndex": 0,
    "explanation": "A node in a doubly linked list contains two pointers: one pointer (typically called 'next') that points to the subsequent node in the list, and another pointer (typically called 'prev' or 'previous') that points to the preceding node in the list. This allows for bidirectional traversal."
  },
  {
    "question": "What happens when an attempt is made to access an array element beyond its declared size?",
    "choices": [
      "Runtime error or undefined behaviour.",
      "Compiler error",
      "The program safely ignores it",
      "The last element is returned instead"
    ],
    "correctIndex": 0,
    "explanation": "Attempting to access an array element beyond its declared bounds (e.g., `arr[10]` for `arr[10]`) results in a runtime error, such as an 'ArrayIndexOutOfBoundsException' in Java or 'segmentation fault' in C/C++. This is considered undefined behavior as the program tries to access memory it doesn't own."
  },
  {
    "question": "Which of the following is a key disadvantage of linked lists?",
    "choices": [
      "They use more memory due to pointers",
      "They do not support dynamic memory allocation",
      "They cannot grow in size",
      "They do not allow insertions and deletions"
    ],
    "correctIndex": 0,
    "explanation": "A significant disadvantage of linked lists compared to arrays is their increased memory consumption. Each node in a linked list stores not only the data but also one or more pointers (e.g., 'next' and 'previous'), which require additional memory space."
  },
  {
    "question": "In a doubly linked list, which pointer facilitates backward traversal?",
    "choices": [
      "Previous pointer",
      "Next pointer",
      "Head pointer",
      "Tail pointer"
    ],
    "correctIndex": 0,
    "explanation": "Each node in a doubly linked list contains a 'previous' pointer (or 'prev') that points to the node immediately preceding it. This pointer is specifically designed to enable efficient traversal of the list in the backward direction."
  },
  {
    "question": "In a circular linked list, the last node points to the ______.",
    "choices": [
      "First node",
      "Last node",
      "Middle node",
      "NULL"
    ],
    "correctIndex": 0,
    "explanation": "In a circular linked list, the 'next' pointer of the last node points back to the first node of the list, forming a continuous circle. This allows traversal from any node to any other node in the list."
  },
  {
    "question": "In a singly linked list, each node contains a pointer to the ______ node.",
    "choices": [
      "Next",
      "Previous",
      "Middle",
      "First"
    ],
    "correctIndex": 0,
    "explanation": "In a singly linked list, each node consists of two parts: the data it holds and a pointer (or reference) that points to the *next* node in the sequence. The last node's pointer typically points to NULL (or equivalent)."
  },
  {
    "question": "The main disadvantage of an array compared to a linked list is its ______ size.",
    "choices": [
      "Fixed",
      "Dynamic",
      "Variable",
      "Adjustable"
    ],
    "correctIndex": 0,
    "explanation": "The primary disadvantage of a static array is its fixed size. Once declared, an array's size cannot be easily changed during runtime. If more elements need to be stored, a new, larger array must be created, and all existing elements copied over, which can be inefficient. Linked lists, in contrast, offer dynamic resizing."
  },
  {
    "question": "How is an element accessed in an array?",
    "choices": [
      "Using an index",
      "Using a key-value pair",
      "By traversing from the first element",
      "By dynamically searching for it"
    ],
    "correctIndex": 0,
    "explanation": "Elements in an array are accessed directly using their numerical index (position). This is known as random access or direct access, and it allows retrieval of any element in O(1) time."
  },
  {
    "question": "What is the best method to insert a node at a specific position in a singly linked list?",
    "choices": [
      "Traverse the list to the desired position and update pointers",
      "Insert the node at the head and shift elements forward",
      "Allocate a new list and merge it with the existing one",
      "Reverse the entire list before inserting"
    ],
    "correctIndex": 0,
    "explanation": "To insert a node at a specific position (not head or tail) in a singly linked list, you must first traverse the list from the head until you reach the node *before* the desired insertion point. Once there, you update the pointers: the new node's 'next' pointer points to the current node at that position, and the previous node's 'next' pointer points to the new node."
  },
  {
    "question": "What type of memory allocation does an array use?",
    "choices": [
      "Contiguous memory allocation",
      "Non-contiguous memory allocation",
      "Linked memory allocation",
      "Fragmented memory allocation"
    ],
    "correctIndex": 0,
    "explanation": "Arrays require contiguous blocks of memory to store their elements. This means all elements are placed one after another in a single, uninterrupted sequence of memory addresses. This contiguity is key to their O(1) random access time."
  },
  {
    "question": "In an array, all elements must be of the same data type.",
    "choices": [
      "True",
      "False"
    ],
    "correctIndex": 0,
    "explanation": "True. A fundamental characteristic of arrays in most strongly-typed programming languages is that all elements stored within a single array must be of the same data type. This allows for uniform memory allocation and efficient access."
  },
  {
    "question": "Which term best describes the ability to directly access any element in an array using its index?",
    "choices": [
      "Random Access",
      "Sequential access",
      "Pointer based access",
      "Indexed access"
    ],
    "correctIndex": 0,
    "explanation": "Random access (or direct access) is the ability to retrieve any item in a data structure with the same amount of time, regardless of its position. Arrays provide random access because the memory address of any element can be directly calculated using its index and the base address of the array, leading to O(1) access time."
  },
  {
    "question": "What is the time complexity of inserting a new node at the beginning of a singly linked list?",
    "choices": [
      "O(1)",
      "O(n)",
      "O(log n)",
      "O(n²)"
    ],
    "correctIndex": 0,
    "explanation": "Inserting a new node at the beginning (head) of a singly linked list is an O(1) operation. You simply create the new node, point its 'next' pointer to the current head, and then update the head pointer to the new node. This doesn't depend on the number of elements in the list."
  },
  {
    "question": "In a singly linked list, what does each node contain?",
    "choices": [
      "Data and a pointer to the next node",
      "Data and a pointer to both previous and next nodes",
      "Only data without any pointer",
      "Multiple pointers to various nodes"
    ],
    "correctIndex": 0,
    "explanation": "A node in a singly linked list fundamentally contains two parts: the data (or value) that it stores, and a pointer (or reference) that points to the subsequent node in the sequence. The last node's pointer typically points to null."
  },
  {
    "question": "What is the main disadvantage of inserting a new node at the tail of a singly linked list without a tail pointer?",
    "choices": [
      "It requires traversing the entire list to find the last node",
      "It is impossible to insert at the tail",
      "The inserted node always points to the head",
      "The inserted node gets lost in memory"
    ],
    "correctIndex": 0,
    "explanation": "Without a separate tail pointer, to insert a new node at the end of a singly linked list, you must start from the head and traverse every node until you reach the current last node. This traversal takes O(N) time, making it an inefficient operation for large lists."
  },
  {
    "question": "Arrays are best suited for applications where ______ is required.",
    "choices": [
      "Fast random access",
      "Frequent insertions and deletions",
      "Dynamic resizing",
      "Storing heterogeneous data types"
    ],
    "correctIndex": 0,
    "explanation": "Arrays excel in scenarios where quick, direct access to elements by their position (index) is paramount. Their contiguous memory allocation enables O(1) random access time, making them highly efficient for lookup operations based on index."
  },
  {
    "question": "Which of the following is a fundamental limitation of an array?",
    "choices": [
      "Fixed size after declaration",
      "Ability to store elements of different types",
      "Inefficient random access",
      "Memory allocation is always dynamic"
    ],
    "correctIndex": 0,
    "explanation": "A fundamental limitation of arrays in many programming languages is their fixed size, determined at the time of declaration or initialization. Once an array is created, its capacity cannot be easily changed, which can lead to issues if the number of elements varies unexpectedly."
  },
  {
    "question": "What is a key difference between an array and a linked list?",
    "choices": [
      "Arrays use contiguous memory, whereas linked lists use non-contiguous memory",
      "Arrays can store different data types, but linked lists cannot",
      "Linked lists allow only fixed-size storage",
      "Arrays do not allow random access"
    ],
    "correctIndex": 0,
    "explanation": "The most significant difference lies in their memory allocation: arrays store elements in a single block of contiguous memory, allowing direct index-based access. Linked lists, conversely, store elements (nodes) in potentially scattered, non-contiguous memory locations, with pointers connecting them sequentially."
  },
  {
    "question": "What is the time complexity of accessing an element at a known index in an array?",
    "choices": [
      "O(1)",
      "O(n)",
      "O(log n)",
      "O(n²)"
    ],
    "correctIndex": 0,
    "explanation": "Accessing an element in an array using its index is a constant-time operation, denoted as O(1). This is because the memory address of the desired element can be directly calculated based on the array's base address, the size of each element, and the given index, without needing to traverse any other elements."
  },
  {
    "question": "What is the best way to merge two sorted linked lists into one sorted list?",
    "choices": [
      "Use two pointers to compare elements and build the merged list",
      "Append the second list to the first, then sort the result",
      "Copy elements to an array, sort the array, then create a new list",
      "Use recursion to rearrange the elements"
    ],
    "correctIndex": 0,
    "explanation": "The most efficient way to merge two *already sorted* linked lists is to use a two-pointer approach. You maintain one pointer for each list, compare the elements they point to, add the smaller element to the new merged list, and advance its corresponding pointer. This continues until both lists are exhausted, resulting in an O(N+M) time complexity (where N and M are the lengths of the lists)."
  },
  {
  "question": "What is the main advantage of using a doubly linked list over a singly linked list?",
  "choices": [
    "Allows traversal in both directions",
    "Uses less memory",
    "Requires no additional pointer space",
    "Faster access to random elements"
  ],
  "correctIndex": 0,
  "explanation": "The primary advantage of a doubly linked list is that each node contains pointers to both the next and the previous nodes. This allows for efficient traversal in both forward and backward directions, which is not possible in a singly linked list without re-traversing from the head."
  },
  {
    "question": "A leaf node is a node that has no children in a binary tree.",
    "choices": [
      "True",
      "False"
    ],
    "correctIndex": 0,
    "explanation": "True. A leaf node (also known as an external node or terminal node) is any node in a tree data structure that does not have any child nodes. It marks the end of a path from the root."
  },
  {
    "question": "The process of removing a node with one child in a BST involves replacing it with ________.",
    "choices": [
      "Its only child",
      "The root node",
      "The maximum node",
      "The minimum node"
    ],
    "correctIndex": 0,
    "explanation": "When deleting a node in a Binary Search Tree (BST) that has only one child, the node is simply replaced by its sole child. The parent of the deleted node then points directly to this child, and the child's parent pointer (if a doubly-linked tree) is updated to the parent of the deleted node."
  },
  {
    "question": "A balanced BST ensures efficient searching, insertion, and deletion.",
    "choices": [
      "True",
      "False"
    ],
    "correctIndex": 0,
    "explanation": "True. A balanced Binary Search Tree (such as an AVL tree or Red-Black tree) maintains a logarithmic height (O(log n)), which guarantees that search, insertion, and deletion operations can be performed in O(log n) time, even in the worst case. An unbalanced BST can degenerate into a linked list, leading to O(n) worst-case time complexity."
  },
  {
    "question": "A tree structure is used to model an organizational chart where each manager can have at most two subordinates. What type of tree is this?",
    "choices": [
      "Binary Tree",
      "Ternary Tree",
      "Heap",
      "AVL Tree"
    ],
    "correctIndex": 0,
    "explanation": "A Binary Tree is defined as a tree data structure where each node has at most two children, typically referred to as the left child and the right child. This perfectly matches the description of a manager having at most two subordinates."
  },
  {
    "question": "What is the time complexity of an in-order traversal in a binary tree with N nodes?",
    "choices": [
      "O(N)",
      "O(log N)",
      "O(N log N)",
      "O(N2)"
    ],
    "correctIndex": 0,
    "explanation": "In-order traversal, like all standard tree traversals (pre-order, post-order, level-order), requires visiting each of the N nodes exactly once. Therefore, the time complexity is linear, O(N)."
  },
  {
    "question": "What happens when you delete a node with two children in a binary tree?",
    "choices": [
      "It is replaced with its in-order successor or predecessor",
      "It is replaced with its left child",
      "It is replaced with its right child",
      "It is deleted without replacement"
    ],
    "correctIndex": 0,
    "explanation": "When deleting a node with two children in a Binary Search Tree, the standard procedure is to replace the deleted node with its in-order successor (the smallest node in its right subtree) or its in-order predecessor (the largest node in its left subtree). This maintains the BST properties."
  },
  {
    "question": "In a binary tree, pre-order traversal always visits the left subtree before the right subtree.",
    "choices": [
      "True",
      "False"
    ],
    "correctIndex": 0,
    "explanation": "True. In pre-order traversal, the order of visiting nodes is: Root -> Left Subtree -> Right Subtree. This means the left subtree is always processed entirely before the right subtree."
  },
  {
    "question": "What is the worst-case height of a BST with N nodes if it is completely unbalanced?",
    "choices": [
      "O(N)",
      "O(log N)",
      "O(N log N)",
      "O(1)"
    ],
    "correctIndex": 0,
    "explanation": "In the worst case, if elements are inserted into a Binary Search Tree in strictly ascending or descending order, the BST degenerates into a skewed tree (like a linked list). In this scenario, the height of the tree becomes N (the number of nodes), leading to a worst-case height of O(N)."
  },
  {
    "question": "What is the average-case time complexity of searching for a value in a balanced Binary Search Tree?",
    "choices": [
      "O(log N)",
      "O(N)",
      "O(N log N)",
      "O(1)"
    ],
    "correctIndex": 0,
    "explanation": "In a balanced Binary Search Tree (BST), the height is always logarithmic (log N). Therefore, searching for a value involves traversing a path from the root to a leaf, which takes O(log N) time on average and in the worst case."
  },
  {
    "question": "The root node of a BST always contains the smallest element in the tree.",
    "choices": [
      "False",
      "True"
    ],
    "correctIndex": 0,
    "explanation": "False. The root node of a Binary Search Tree (BST) can contain any value. The defining property of a BST is that all nodes in its left subtree have values smaller than the root, and all nodes in its right subtree have values larger than the root. The smallest element is always the leftmost node in the tree."
  },
  {
    "question": "In a binary tree, _______ traversal method is used to find the correct position for inserting a new node.",
    "choices": [
      "Level-order",
      "Pre-order",
      "Post-order",
      "In-order"
    ],
    "correctIndex": 0,
    "explanation": "When inserting a node into a Binary Search Tree (which is a specific type of binary tree), the search for the correct insertion position follows a path from the root, comparing the new node's value with current node's value. This is essentially a search operation, not a specific traversal *method* like pre-order or in-order. However, if referring to a general binary tree where structure matters, level-order traversal (or breadth-first search) might be used to find the first available spot or maintain completeness."
  },
  {
    "question": "A binary tree traversal where the left subtree is visited first, followed by the right subtree, and then the root, is known as:",
    "choices": [
      "Post-order",
      "Pre-order",
      "In-order",
      "Level-order"
    ],
    "correctIndex": 0,
    "explanation": "Post-order traversal follows the order: Left Subtree -> Right Subtree -> Root. The root node is visited last among the nodes of its subtree."
  },
  {
    "question": "Which data structure ensures an efficient search operation similar to a BST but is always balanced?",
    "choices": [
      "AVL Tree",
      "Heap",
      "Stack",
      "Queue"
    ],
    "correctIndex": 0,
    "explanation": "An AVL Tree is a self-balancing Binary Search Tree. It automatically rebalances itself after insertions and deletions to ensure that the height difference between the left and right subtrees of any node is at most 1. This guarantee maintains a logarithmic height, leading to O(log n) time complexity for search, insert, and delete operations."
  },
  {
    "question": "Which data structure is commonly used to perform level-order traversal in a binary tree?",
    "choices": [
      "Queue",
      "Stack",
      "Heap",
      "Linked List"
    ],
    "correctIndex": 0,
    "explanation": "Level-order traversal (also known as Breadth-First Search) visits nodes level by level, from left to right. A Queue data structure is ideally suited for this. You enqueue the root, then repeatedly dequeue a node, process it, and enqueue its children, ensuring nodes at the same level are processed before moving to the next level."
  },
  {
    "question": "What is the time complexity of inserting an element in a balanced binary tree?",
    "choices": [
      "O(log n)",
      "O(n)",
      "O(1)",
      "O(n log n)"
    ],
    "correctIndex": 0,
    "explanation": "In a balanced binary tree (like an AVL tree or Red-Black tree), the height of the tree is maintained at O(log n). Inserting an element involves searching for the correct position (O(log n)) and potentially performing rotations to rebalance the tree (also O(log n)). Thus, the overall time complexity for insertion is O(log n)."
  },
  {
    "question": "In a binary tree, each node can have at most how many children?",
    "choices": [
      "2",
      "3",
      "4",
      "Unlimited"
    ],
    "correctIndex": 0,
    "explanation": "By definition, a binary tree is a tree data structure in which each node has at most two children, commonly referred to as the left child and the right child."
  },
  {
    "question": "Which traversal method of a BST returns its elements in sorted order?",
    "choices": [
      "In-order",
      "Pre-order",
      "Post-order",
      "Level-order"
    ],
    "correctIndex": 0,
    "explanation": "In-order traversal (Left -> Root -> Right) of a Binary Search Tree (BST) consistently visits nodes in ascending order of their values. This property makes it very useful for obtaining a sorted list of elements from a BST."
  },
  {
    "question": "A binary tree with N nodes always has N-1 edges.",
    "choices": [
      "True",
      "False"
    ],
    "correctIndex": 0,
    "explanation": "True. For any tree structure with N nodes, there are always exactly N-1 edges. This is a fundamental property of trees, as each node (except the root) has exactly one incoming edge from its parent."
  },
  {
    "question": "What type of data structure is generally used to implement an iterative in-order traversal?",
    "choices": [
      "Stack",
      "Queue",
      "Linked List",
      "Heap"
    ],
    "correctIndex": 0,
    "explanation": "Iterative in-order traversal of a binary tree typically uses a Stack. The algorithm involves pushing nodes onto the stack as you traverse down the left subtree, then popping nodes to visit them, and finally moving to the right subtree."
  },
  {
    "question": "Which tree traversal method processes the root node first, then the left subtree, and finally the right subtree?",
    "choices": [
      "Pre-order",
      "In-order",
      "Post-order",
      "Level-order"
    ],
    "correctIndex": 0,
    "explanation": "Pre-order traversal follows the order: Root -> Left Subtree -> Right Subtree. The root node is processed before its subtrees."
  },
  {
    "question": "The maximum number of nodes at level L of a binary tree is ________.",
    "choices": [
      "2L",
      "L2",
      "L * 2",
      "log L"
    ],
    "correctIndex": 0,
    "explanation": "Assuming the root is at level 0, the maximum number of nodes at level L (depth L) in a binary tree is $2^L$. Each level can potentially double the number of nodes from the previous level."
  },
  {
    "question": "In pre-order traversal, the root node is processed ________ visiting its left and right subtrees.",
    "choices": [
      "Before",
      "After",
      "Between",
      "Never"
    ],
    "correctIndex": 0,
    "explanation": "In pre-order traversal, the sequence is Root -> Left Subtree -> Right Subtree. This means the root node is processed *before* any of its children or descendants in its subtrees."
  },
  {
    "question": "The in-order successor of a node in a BST is the node with the smallest value in its ________ subtree.",
    "choices": [
      "Right",
      "Left",
      "Parent",
      "Root"
    ],
    "correctIndex": 0,
    "explanation": "For a node in a Binary Search Tree (BST) that has a right child, its in-order successor is the node with the smallest value in its *right* subtree. This is found by going once to the right child and then continually going left until a node with no left child is found."
  },
  {
    "question": "The traversal order that follows Left → Root → Right in a binary tree is called ________ traversal.",
    "choices": [
      "In-order",
      "Pre-order",
      "Post-order",
      "Level-order"
    ],
    "correctIndex": 0,
    "explanation": "In-order traversal is defined by the sequence: Left Subtree -> Root -> Right Subtree. When applied to a Binary Search Tree, this traversal method outputs the nodes in sorted (ascending) order."
  },
  {
    "question": "A binary tree is full when:",
    "choices": [
      "Every node has 0 or 2 children",
      "Every level is completely filled",
      "Every node has exactly 1 child",
      "The left subtree has more nodes than the right"
    ],
    "correctIndex": 0,
    "explanation": "A full binary tree (sometimes called a strictly binary tree) is a tree in which every node has either zero or two children. This means there are no nodes with only one child."
  },
  {
    "question": "A ________ binary tree is one in which all levels are entirely filled, except perhaps the last level, which is filled from left to right.",
    "choices": [
      "Complete",
      "Full",
      "Balanced",
      "Heap"
    ],
    "correctIndex": 0,
    "explanation": "A complete binary tree is a binary tree in which all levels are completely filled, except possibly the last level, which is filled from left to right. This property is important for efficient array-based implementations of binary trees, especially heaps."
  },
  {
    "question": "Which traversal method visits nodes in sorted order when applied to a Binary Search Tree?",
    "choices": [
      "In-order",
      "Pre-order",
      "Post-order",
      "Level-order"
    ],
    "correctIndex": 0,
    "explanation": "In-order traversal (Left -> Root -> Right) of a Binary Search Tree (BST) guarantees that the nodes are visited in ascending order of their keys. This is a fundamental property that makes in-order traversal highly useful for BSTs."
  },
  {
    "question": "What is the primary property of a Binary Search Tree (BST)?",
    "choices": [
      "Left subtree nodes have smaller values than the root, and right subtree nodes have larger values.",
      "Every node has at most two children.",
      "All nodes have equal values.",
      "Nodes are arranged in a complete binary tree structure."
    ],
    "correctIndex": 0,
    "explanation": "The defining property of a Binary Search Tree (BST) is that for any given node, all values in its left subtree are less than the node's value, and all values in its right subtree are greater than the node's value. This recursive property enables efficient searching."
  },
  {
    "question": "In post-order traversal, the root node is the first node to be processed.",
    "choices": [
      "False",
      "True"
    ],
    "correctIndex": 0,
    "explanation": "False. In post-order traversal, the sequence is Left Subtree -> Right Subtree -> Root. The root node is processed *last* among the nodes of its subtree."
  },
  {
    "question": "In a binary search tree (BST), which node is typically used to replace a node with two children during deletion?",
    "choices": [
      "Its in-order successor or predecessor.",
      "Its left child.",
      "Its right child.",
      "Any random node from the tree."
    ],
    "correctIndex": 0,
    "explanation": "When a node with two children is deleted from a BST, it is typically replaced by its in-order successor (the smallest node in its right subtree) or its in-order predecessor (the largest node in its left subtree). This maintains the BST property and ensures that the structure remains valid."
  },
   {
    "question": "Which of the following is a fundamental concept of recursion in trees?",
    "choices": [
      "A function calls itself",
      "Loops are used instead of function calls",
      "Recursion is only used in binary trees",
      "A tree must be fully balanced to use recursion"
    ],
    "correctIndex": 0,
    "explanation": "Recursion in programming involves a function calling itself, either directly or indirectly. This concept is fundamental to many tree algorithms because trees have a recursive structure: each subtree is itself a tree, allowing operations on a node to be defined in terms of the same operations on its children."
  },
  {
    "question": "In a max-heap, the value of each parent node is ______ than or equal to the values of its child nodes.",
    "choices": [
      "Greater",
      "Less",
      "Equal",
      "Divisible"
    ],
    "correctIndex": 0,
    "explanation": "In a max-heap, the heap property states that for every node 'i' other than the root, the value of node 'i' is less than or equal to the value of its parent. Equivalently, the parent node's value is always greater than or equal to the values of its children."
  },
  {
    "question": "A recursive function for tree traversal typically consists of a ______ condition and recursive calls for subtrees.",
    "choices": [
      "Base",
      "Loop",
      "Infinite",
      "Stack"
    ],
    "correctIndex": 0,
    "explanation": "A recursive function always needs a base condition (or base case) to stop the recursion and prevent infinite loops. In tree traversals, the base case is typically when a null node or a leaf node is encountered."
  },
  {
    "question": "What is the time complexity of extracting the minimum element from a min heap?",
    "choices": [
      "O(log n)",
      "O(1)",
      "O(n)",
      "O(n log n)"
    ],
    "correctIndex": 0,
    "explanation": "Extracting the minimum element from a min-heap involves removing the root (O(1)), moving the last element to the root, and then 'heapifying down' (or bubbling down) this new root to restore the heap property. Heapifying down takes O(log n) time, as it involves comparisons and swaps along a path from the root to a leaf, which is proportional to the height of the heap."
  },
  {
    "question": "What is the time complexity of a recursive in-order traversal in a balanced binary tree with n nodes?",
    "choices": [
      "O(n)",
      "O(1)",
      "O(n log n)",
      "O(log n)"
    ],
    "correctIndex": 0,
    "explanation": "All standard tree traversals (in-order, pre-order, post-order, level-order) visit each node in the tree exactly once. Regardless of whether the tree is balanced or not, and regardless of the specific traversal type, visiting all 'n' nodes will take linear time, i.e., O(n)."
  },
  {
    "question": "What happens when you remove the root from a max heap?",
    "choices": [
      "The largest element is removed, and the heap is restructured",
      "The smallest element is removed",
      "The tree is completely reconstructed",
      "The heap becomes unbalanced"
    ],
    "correctIndex": 0,
    "explanation": "In a max-heap, the root node always contains the largest element. When the root is removed (extracted), the last element of the heap is typically moved to the root position. Then, a 'heapify-down' operation is performed to sink this element to its correct position, thereby restoring the max-heap property and restructuring the heap."
  },
  {
    "question": "Which recursive approach is commonly used to find the height of a binary tree?",
    "choices": [
      "Return the maximum depth of the left and right subtrees plus one",
      "Count the number of nodes in the left subtree only",
      "Traverse the tree iteratively",
      "Return the sum of all node values"
    ],
    "correctIndex": 0,
    "explanation": "The height of a binary tree can be recursively defined as 1 (for the root) plus the maximum of the heights of its left and right subtrees. The base case is a null node, which has a height of -1 (or 0, depending on definition)."
  },
  {
    "question": "Which sorting algorithm uses a binary heap to achieve O(n log n) complexity?",
    "choices": [
      "Heap Sort",
      "Quick Sort",
      "Merge Sort",
      "Bubble Sort"
    ],
    "correctIndex": 0,
    "explanation": "Heap Sort is a comparison-based sorting algorithm that uses a binary heap data structure. It works by first building a max-heap (or min-heap) from the input array and then repeatedly extracting the maximum (or minimum) element from the heap and placing it at the end (or beginning) of the sorted array. Both building the heap and extracting elements take O(n log n) time."
  },
  {
    "question": "In a priority queue implemented using a heap, how do you decrease the priority of an element?",
    "choices": [
      "Decrease its key value and apply heapify",
      "Remove and reinsert the element",
      "Increase its key value",
      "Move it to the root"
    ],
    "correctIndex": 0,
    "explanation": "To decrease the priority of an element in a min-heap (or increase priority in a max-heap), you update its key value to a smaller number. Since its priority has decreased, it might need to move further down the heap to maintain the heap property. This is achieved by performing a 'heapify-down' (or 'sift-down') operation, also known as 'bubble-down'."
  },
  {
    "question": "In an AVL tree, what is the time complexity of searching for an element?",
    "choices": [
      "O(log n)",
      "O(1)",
      "O(n)",
      "O(n log n)"
    ],
    "correctIndex": 0,
    "explanation": "AVL trees are self-balancing Binary Search Trees. They guarantee that the height of the tree is always logarithmic (O(log n)) with respect to the number of nodes. Therefore, searching for an element, which involves traversing a path from the root to a potential leaf, takes O(log n) time in the worst case."
  },
  {
    "question": "True or False: A pre-order traversal visits the root node before its left and right subtrees.",
    "choices": [
      "True",
      "False"
    ],
    "correctIndex": 0,
    "explanation": "True. The definition of pre-order traversal is: visit the Root, then recursively traverse the Left subtree, then recursively traverse the Right subtree."
  },
  {
    "question": "A post-order traversal is particularly useful for ______ trees before deletion.",
    "choices": [
      "Deleting",
      "Searching",
      "Sorting",
      "Coloring"
    ],
    "correctIndex": 0,
    "explanation": "Post-order traversal (Left -> Right -> Root) is useful for deleting a tree or its nodes. Because the root is visited last, you can delete its children (and their subtrees) first, ensuring that when you delete a node, its children have already been processed or deleted, preventing memory leaks or dangling pointers in a recursive deletion process."
  },
  {
    "question": "Which data structure is best suited for implementing a priority queue?",
    "choices": [
      "Heap",
      "Stack",
      "Queue",
      "Linked List"
    ],
    "correctIndex": 0,
    "explanation": "A heap (specifically a binary heap) is the most common and efficient data structure for implementing a priority queue. It allows for O(1) access to the highest/lowest priority element (the root) and O(log n) time complexity for insertion and extraction of elements, which are the primary operations of a priority queue."
  },
  {
    "question": "How does a Red-Black tree resolve a violation when two consecutive red nodes appear after insertion?",
    "choices": [
      "Recoloring and rotations are applied to fix the issue",
      "The tree remains unchanged",
      "The violating node is recolored to black",
      "The violating node is deleted"
    ],
    "correctIndex": 0,
    "explanation": "Red-Black trees maintain their balance and properties (including no two consecutive red nodes) through a combination of recoloring nodes and performing tree rotations (left rotations and right rotations) whenever an insertion or deletion violates one of its rules."
  },
  {
    "question": "True or False: In an AVL tree, every node must have two children.",
    "choices": [
      "False",
      "True"
    ],
    "correctIndex": 0,
    "explanation": "False. An AVL tree is a self-balancing binary *search* tree. While it maintains a balanced height (balance factor between -1 and 1 for every node), it does not require every node to have two children. Leaf nodes have zero children, and internal nodes can have one or two children as long as the balance property is maintained."
  },
  {
    "question": "A node in an AVL tree is considered unbalanced when the height difference between its left and right subtrees is greater than ____.",
    "choices": [
      "1",
      "2",
      "3",
      "4"
    ],
    "correctIndex": 0,
    "explanation": "In an AVL tree, the balance factor for any node is defined as the height of its left subtree minus the height of its right subtree. An AVL tree maintains balance by ensuring that the absolute value of this balance factor is at most 1 (i.e., -1, 0, or 1)."
  },
  {
    "question": "The two main techniques used in dynamic programming to store intermediate results are ______ and tabulation.",
    "choices": [
      "Memorization",
      "Sorting",
      "Brute force",
      "Approximation"
    ],
    "correctIndex": 0,
    "explanation": "The two primary techniques in dynamic programming are memoization (top-down approach with caching results of recursive calls) and tabulation (bottom-up approach building up solutions for smaller subproblems in a table)."
  },
  {
    "question": "What is the main difference between dynamic programming and divide and conquer?",
    "choices": [
      "Divide and conquer solves overlapping subproblems separately",
      "Dynamic programming solves problems by breaking them into non-overlapping subproblems",
      "Dynamic programming does not use recursion",
      "Dynamic programming cannot be applied to optimization problems"
    ],
    "correctIndex": 0,
    "explanation": "The key difference is how they handle subproblems. Divide and conquer (e.g., Merge Sort, Quick Sort) solves distinct (non-overlapping) subproblems recursively. Dynamic programming is used when subproblems *overlap*, meaning the same subproblems are encountered multiple times. Dynamic programming solves each overlapping subproblem only once and stores its result to avoid recomputation."
  },
  {
    "question": "A problem exhibits ______ subproblems if smaller instances of the problem are solved multiple times.",
    "choices": [
      "Overlapping",
      "Independent",
      "Unique",
      "Irrelevant"
    ],
    "correctIndex": 0,
    "explanation": "A problem has 'overlapping subproblems' if the same subproblems are re-computed multiple times when solving the larger problem using a recursive approach. This is a key characteristic that makes dynamic programming an efficient solution strategy."
  },
  {
    "question": "What is the base case in a recursive tree traversal algorithm?",
    "choices": [
      "When a node has no children (leaf node)",
      "When a node has two children",
      "When the tree is empty",
      "When the recursion depth reaches 10"
    ],
    "correctIndex": 0,
    "explanation": "In recursive tree traversal, the base case is typically when the current node being processed is NULL (empty). This is the condition that stops the recursion from going infinitely deep. In some contexts, reaching a leaf node can also be considered a base case if specific operations are performed there."
  },
  {
    "question": "Which of the following problems can be efficiently solved using dynamic programming?",
    "choices": [
      "Fibonacci sequence",
      "Tower of Hanoi",
      "Binary search",
      "Quick sort"
    ],
    "correctIndex": 0,
    "explanation": "The Fibonacci sequence problem (`F(n) = F(n-1) + F(n-2)`) exhibits overlapping subproblems (e.g., `F(3)` is computed multiple times in a naive recursive solution for `F(5)`). Dynamic programming (either memoization or tabulation) efficiently solves this by storing previously computed Fibonacci numbers."
  },
  {
    "question": "Which type of problem can dynamic programming solve efficiently?",
    "choices": [
      "Problems with overlapping subproblems",
      "Problems with independent subproblems",
      "Problems with no optimal substructure",
      "Problems where solutions must be guessed"
    ],
    "correctIndex": 0,
    "explanation": "Dynamic programming is particularly effective for problems that exhibit two main properties: optimal substructure (an optimal solution to a problem can be constructed from optimal solutions of its subproblems) and overlapping subproblems (the same subproblems are encountered repeatedly)."
  },
  {
    "question": "Which tree traversal visits nodes in the order: left subtree, root, right subtree?",
    "choices": [
      "In-order",
      "Pre-order",
      "Post-order",
      "Level-order"
    ],
    "correctIndex": 0,
    "explanation": "This describes the In-order traversal. The sequence is Left Subtree -> Root -> Right Subtree. For a Binary Search Tree, this traversal yields the elements in sorted order."
  },
  {
    "question": "The time complexity of inserting an element into a binary heap is typically ______, assuming a well-balanced heap structure.",
    "choices": [
      "O(log n)",
      "O(1)",
      "O(n)",
      "O(n log n)"
    ],
    "correctIndex": 0,
    "explanation": "Inserting an element into a binary heap (max-heap or min-heap) involves adding the new element at the end of the heap (which takes O(1) if implemented with an array) and then 'heapifying up' (or bubbling up) this element to its correct position to maintain the heap property. This 'sift-up' operation takes time proportional to the height of the heap, which is O(log n)."
  },
  {
    "question": "Which of the following property defines a binary heap?",
    "choices": [
      "Every level except the last is completely filled",
      "The root must always be the largest element",
      "It must be a full binary tree",
      "The parent node must always have at most one child"
    ],
    "correctIndex": 0,
    "explanation": "A binary heap is a complete binary tree that satisfies the heap property. A complete binary tree is one in which all levels are completely filled, except possibly the last level, which is filled from left to right. This structural property is essential for efficient array-based implementation."
  },
  {
    "question": "Which operation helps maintain balance in a Red-Black tree after insertion?",
    "choices": [
      "Rotations and recoloring",
      "Only recoloring",
      "Only rotations",
      "Deleting the root"
    ],
    "correctIndex": 0,
    "explanation": "Red-Black trees maintain their balance properties (like 'no two consecutive red nodes' and 'same number of black nodes on any path from root to leaf') by performing a combination of node recoloring and tree rotations (left and right rotations) when an insertion or deletion causes a violation."
  },
  {
    "question": "What is the maximum height difference allowed between left and right subtrees in an AVL tree?",
    "choices": [
      "1",
      "0",
      "2",
      "No limit"
    ],
    "correctIndex": 0,
    "explanation": "An AVL tree is a self-balancing binary search tree where the height difference between the left and right subtrees of any node (its balance factor) is always -1, 0, or 1. If this difference exceeds 1 (or is less than -1), rotations are performed to restore balance."
  },
  {
    "question": "What is the worst-case time complexity of inserting a node in an AVL tree?",
    "choices": [
      "O(log n)",
      "O(n)",
      "O(n log n)",
      "O(1)"
    ],
    "correctIndex": 0,
    "explanation": "Inserting a node into an AVL tree involves finding the correct position (which is O(log n) due to the balanced nature) and potentially performing rotations to rebalance the tree. The rebalancing operations also take O(log n) time. Therefore, the overall worst-case time complexity for insertion is O(log n)."
  },
  {
    "question": "Which of the following properties is unique to AVL trees but not necessarily guaranteed to Red-Black trees?",
    "choices": [
      "The balance factor of any node is between -1 and 1",
      "Every path from root to leaf has the same number of black nodes",
      "The tree is always strictly balanced",
      "The tree allows duplicate keys"
    ],
    "correctIndex": 0,
    "explanation": "The strict balance factor constraint (height difference of left and right subtrees being at most 1) is a defining characteristic of AVL trees. Red-Black trees are also balanced, but their balance property ('every path from root to leaf has the same number of black nodes') allows for a greater height difference between subtrees than AVL trees, though still logarithmic."
  },
  {
    "question": "Which of the following problems is best suited for dynamic programming?",
    "choices": [
      "Finding the minimum number of coins for change",
      "Finding the shortest path in an unweighted graph",
      "Performing a binary search",
      "Sorting an array"
    ],
    "correctIndex": 0,
    "explanation": "The 'minimum number of coins for change' problem exhibits both optimal substructure (the optimal solution for an amount can be found using optimal solutions for smaller amounts) and overlapping subproblems (the same sub-amounts are often evaluated multiple times). This makes it an ideal candidate for dynamic programming, usually solved with a bottom-up approach (tabulation)."
  },
  {
    "question": "Which of the following hashing methods uses a second hash function to resolve collisions?",
    "choices": [
      "Double Hashing",
      "Quadratic Probing",
      "Separate Chaining",
      "Linear Probing"
    ],
    "correctIndex": 0,
    "explanation": "Double Hashing is an open addressing collision resolution technique where, if a collision occurs with the primary hash function, a second, independent hash function is used to determine the step size for probing the hash table."
  },
  {
    "question": "Which searching algorithm is used in databases for fast lookups?",
    "choices": [
      "Binary search",
      "Linear search",
      "Bubble sort",
      "Insertion sort"
    ],
    "correctIndex": 0,
    "explanation": "Binary search is efficient for fast lookups in sorted data. While databases use various indexing techniques (like B-trees, which are related to binary search trees) for fast lookups, the underlying principle for range queries and specific value lookups in ordered data often leverages concepts similar to binary search."
  },
  {
    "question": "Which pattern matching algorithm is most efficient for DNA sequence matching when dealing with long repeating substrings?",
    "choices": [
      "Knuth-Morris-Pratt (KMP)",
      "Rabin-Karp",
      "Naive String Matching",
      "Boyer-Moore"
    ],
    "correctIndex": 0,
    "explanation": "The Knuth-Morris-Pratt (KMP) algorithm excels in situations with repeating patterns (like in DNA sequences). It preprocesses the pattern to build a Longest Prefix Suffix (LPS) array, which allows it to efficiently skip characters in the text, avoiding redundant comparisons when mismatches occur after a partial match."
  },
  {
    "question": "What is the primary issue with hash tables when handling duplicate keys?",
    "choices": [
      "Collisions occur more frequently",
      "They take up more memory",
      "The hash function must be modified",
      "They require additional sorting operations"
    ],
    "correctIndex": 0,
    "explanation": "When handling duplicate keys, hash tables are more likely to experience collisions because multiple keys map to the same hash bucket or index. Efficient collision resolution strategies become even more crucial in such scenarios."
  },
  {
    "question": "Which of the following is a common hashing technique?",
    "choices": [
      "Linear Probing",
      "Quick Sort",
      "Binary Search",
      "Dijkstra’s Algorithm"
    ],
    "correctIndex": 0,
    "explanation": "Linear Probing is a common collision resolution technique used in hash tables when implementing open addressing. Quick Sort is a sorting algorithm, Binary Search is a searching algorithm, and Dijkstra's Algorithm is a graph algorithm."
  },
  {
    "question": "How does binary search narrow down the search space?",
    "choices": [
      "By dividing it into two halves",
      "By doubling the range",
      "By checking all elements",
      "By sorting the array"
    ],
    "correctIndex": 0,
    "explanation": "Binary search works on sorted data. In each step, it compares the target value with the middle element of the current search space. Based on the comparison, it eliminates half of the remaining search space, effectively dividing it into two halves until the element is found or the search space is exhausted."
  },
  {
    "question": "What is the worst-case time complexity of the linear search algorithm?",
    "choices": [
      "O(n)",
      "O(log n)",
      "O(1)",
      "O(n2)"
    ],
    "correctIndex": 0,
    "explanation": "In the worst case for linear search, the target element is either at the very end of the array or not present at all. In both scenarios, the algorithm has to check every element, leading to a time complexity directly proportional to the number of elements 'n', hence O(n)."
  },
  {
    "question": "Which searching algorithm is commonly implemented using recursion?",
    "choices": [
      "Binary search",
      "Linear search",
      "Bubble search",
      "Hash search"
    ],
    "correctIndex": 0,
    "explanation": "Binary search is inherently recursive. It repeatedly divides the search interval in half. This recursive nature (search in left half or right half) makes it a common candidate for recursive implementation, although it can also be implemented iteratively."
  },
  {
    "question": "Which of the following hashing techniques resolves collisions by storing multiple elements in the same bucket?",
    "choices": [
      "Separate Chaining",
      "Linear Probing",
      "Quadratic Probing",
      "Double Hashing"
    ],
    "correctIndex": 0,
    "explanation": "Separate Chaining is a collision resolution technique where each slot in the hash table is a pointer to a linked list (or another data structure) that contains all the elements that hash to that slot. When a collision occurs, the new element is simply added to the linked list at that bucket."
  },
  {
    "question": "Which string-matching algorithm is best suited for searching multiple patterns simultaneously?",
    "choices": [
      "Aho-Corasick Algorithm",
      "Knuth-Morris-Pratt (KMP) Algorithm",
      "Naive String-Matching Algorithm",
      "Brute Force Algorithm"
    ],
    "correctIndex": 0,
    "explanation": "The Aho-Corasick algorithm is specifically designed for multi-pattern string matching. It constructs a finite automaton (based on a trie) that allows efficient simultaneous searching for all patterns in a given text."
  },
  {
    "question": "What happens when the load factor of a hash table becomes too high?",
    "choices": [
      "Performance degrades due to increased collisions",
      "The hash table crashes",
      "The hash function stops working",
      "All elements are deleted"
    ],
    "correctIndex": 0,
    "explanation": "The load factor of a hash table is the ratio of the number of elements to the number of available slots. When this ratio becomes too high, it means the table is getting full, leading to a significant increase in collisions. This, in turn, increases the time required for insertion, deletion, and search operations, degrading performance."
  },
  {
    "question": "What is the worst-case time complexity of searching in a hash table?",
    "choices": [
      "O(n)",
      "O(log n)",
      "O(1)",
      "O(n²)"
    ],
    "correctIndex": 0,
    "explanation": "In the worst case, especially with a poorly chosen hash function or a high load factor, all elements might hash to the same bucket (in separate chaining) or cause a long chain of probes (in open addressing). In such a scenario, searching can degenerate to O(n), similar to a linear search through a linked list or an array."
  },
  {
    "question": "The Knuth-Morris-Pratt (KMP) algorithm is most efficient for:",
    "choices": [
      "Patterns with repeating prefixes",
      "Random text with no repetition",
      "Large text with small patterns",
      "Small text with large patterns"
    ],
    "correctIndex": 0,
    "explanation": "KMP is particularly efficient when the pattern itself contains significant repetitions (i.e., patterns with repeating prefixes and suffixes). The algorithm preprocesses the pattern to identify these repetitions, which allows it to avoid re-comparing characters that are already known to match, leading to significant performance gains in such cases."
  },
  {
    "question": "What is the primary goal of pattern matching algorithms?",
    "choices": [
      "Finding occurrences of a pattern in a text",
      "Sorting strings",
      "Encrypting text",
      "Counting the number of words in a string"
    ],
    "correctIndex": 0,
    "explanation": "The primary goal of pattern matching algorithms (also known as string searching algorithms) is to find all occurrences (or the first occurrence) of a given 'pattern' string within a larger 'text' string."
  },
  {
    "question": "In an array of 1000 elements, how many comparisons does binary search make in the worst case?",
    "choices": [
      "Around 10",
      "Around 100",
      "Around 500",
      "1000"
    ],
    "correctIndex": 0,
    "explanation": "Binary search's time complexity is O(log n). For n=1000, log₂1000 is approximately 9.96. So, in the worst case, it would take about 10 comparisons to find an element or determine its absence."
  },
  {
    "question": "If a list contains duplicate values, what index does the linear search return when searching for a target value?",
    "choices": [
      "The index of the first occurrence",
      "The index of the last occurrence",
      "All indexes of the target value",
      "An error"
    ],
    "correctIndex": 0,
    "explanation": "Linear search typically traverses the list from the beginning. As soon as it finds the target value, it returns its index and stops. Therefore, it will return the index of the first occurrence if duplicates exist."
  },
  {
    "question": "______________ is a major disadvantage of the linear search algorithm.",
    "choices": [
      "Slow for large datasets",
      "Works only with sorted arrays",
      "Requires additional memory",
      "Does not work with negative numbers"
    ],
    "correctIndex": 0,
    "explanation": "Linear search has a worst-case time complexity of O(n), meaning the time taken grows linearly with the size of the dataset. For very large datasets, this can be extremely slow and inefficient."
  },
  {
    "question": "What is the main drawback of the naive pattern matching algorithm?",
    "choices": [
      "High time complexity due to excessive comparisons",
      "Requires large memory for preprocessing",
      "It cannot find multiple occurrences of a pattern",
      "Only works for numerical strings"
    ],
    "correctIndex": 0,
    "explanation": "The naive (or brute-force) pattern matching algorithm compares the pattern with every possible substring of the text. In the worst case, this can lead to O(mn) time complexity (where m is pattern length, n is text length) due to redundant character comparisons after a mismatch, making it inefficient for large texts or patterns."
  },
  {
    "question": "___________ is the primary purpose of a hash table.",
    "choices": [
      "Storing data in key-value pairs for quick retrieval",
      "Sorting data",
      "Encrypting sensitive information",
      "Storing data in sequential order"
    ],
    "correctIndex": 0,
    "explanation": "Hash tables (or hash maps) are designed for efficient storage and retrieval of data based on a key. They map keys to indices in an array using a hash function, aiming for average O(1) time complexity for insertions, deletions, and lookups."
  },
  {
    "question": "Which of the following is a drawback of open addressing?",
    "choices": [
      "Slower performance when the table is nearly full",
      "Wastes memory due to linked lists",
      "Requires additional hash functions",
      "Cannot store duplicate keys"
    ],
    "correctIndex": 0,
    "explanation": "In open addressing, as the hash table fills up (high load factor), collisions become more frequent. This leads to longer probe sequences to find an empty slot or the desired key, significantly degrading performance. This issue is known as clustering."
  },
  {
    "question": "What is the worst-case time complexity of the binary search algorithm?",
    "choices": [
      "O(log n)",
      "O(n)",
      "O(1)",
      "O(n2)"
    ],
    "correctIndex": 0,
    "explanation": "Binary search repeatedly divides the search space in half. This logarithmic reduction means that the number of comparisons grows proportionally to the logarithm of the number of elements 'n', hence O(log n) in the worst case."
  },
  {
    "question": "Binary search cannot be applied to which type of data structure?",
    "choices": [
      "An unsorted array",
      "A sorted array",
      "A sorted linked list",
      "A list with unique elements"
    ],
    "correctIndex": 0,
    "explanation": "Binary search fundamentally relies on the data being sorted to efficiently narrow down the search space. If the array is unsorted, binary search will not work correctly, as it cannot assume anything about the order of elements in the halves it examines."
  },
  {
    "question": "What is the 'load factor' in the context of hash tables?",
    "choices": [
      "The ratio of used slots to total slots in the table",
      "The total number of collisions",
      "The number of hash functions used",
      "The number of keys stored in the table"
    ],
    "correctIndex": 0,
    "explanation": "The load factor (usually denoted by $\\alpha$) is a measure of how full a hash table is. It is calculated as the number of stored items divided by the total number of available buckets (or slots) in the table. It is crucial for determining a hash table's performance."
  },
  {
    "question": "What is the worst-case time complexity of the Knuth-Morris-Pratt (KMP) algorithm?",
    "choices": [
      "O(n + m)",
      "O(n²)",
      "O(n log m)",
      "O(m log n)"
    ],
    "correctIndex": 0,
    "explanation": "The KMP algorithm has a worst-case time complexity of O(n + m), where 'n' is the length of the text and 'm' is the length of the pattern. This is because it preprocesses the pattern in O(m) time and then performs the search in O(n) time, making it highly efficient."
  },
  {
    "question": "Which type of probing reduces clustering in hash tables?",
    "choices": [
      "Quadratic Probing",
      "Linear Probing",
      "Separate Chaining",
      "Chained Hashing"
    ],
    "correctIndex": 0,
    "explanation": "Quadratic Probing helps to reduce primary clustering, which is a common problem with linear probing. Instead of searching linearly for the next available slot, quadratic probing uses a quadratic increment to find the next slot (e.g., $h(k) + i^2$ for the $i$-th probe), spreading out the probes more effectively."
  },
  {
    "question": "What is the main advantage of Knuth-Morris-Pratt (KMP) over the Naïve approach?",
    "choices": [
      "Avoids redundant comparisons",
      "Uses extra memory for hashing",
      "Always finds the longest pattern",
      "Works only for numeric patterns"
    ],
    "correctIndex": 0,
    "explanation": "KMP's main advantage is its ability to avoid redundant comparisons. By leveraging information about the pattern's structure (specifically, common prefixes and suffixes), it knows how much to shift the pattern after a mismatch without needing to re-examine already matched characters in the text."
  },
  {
    "question": "Which pattern matching algorithm is most effective for searching short patterns in long texts?",
    "choices": [
      "Boyer-Moore Algorithm",
      "Knuth-Morris-Pratt (KMP) Algorithm",
      "Naive Pattern Matching Algorithm",
      "Brute Force Algorithm"
    ],
    "correctIndex": 0,
    "explanation": "The Boyer-Moore algorithm is often considered the most efficient practical string-matching algorithm for a wide range of applications, especially when searching for relatively short patterns within very long texts. It achieves this by starting comparisons from the end of the pattern and making larger jumps when a mismatch occurs, leveraging bad character and good suffix rules."
  },
  {
    "question": "Which string-matching algorithm efficiently avoids unnecessary comparisons, making it suitable for structured binary data search?",
    "choices": [
      "Knuth-Morris-Pratt (KMP) Algorithm",
      "Rabin-Karp Algorithm",
      "Boyer-Moore Algorithm",
      "Aho-Corasick Algorithm"
    ],
    "correctIndex": 0,
    "explanation": "The Knuth-Morris-Pratt (KMP) algorithm's efficiency comes from its ability to avoid unnecessary comparisons by intelligently shifting the pattern. This makes it particularly suitable for searching in structured data, including binary data, where specific byte sequences represent patterns."
  },
  {
    "question": "What does the Knuth-Morris-Pratt (KMP) algorithm use to avoid unnecessary comparisons?",
    "choices": [
      "A prefix-suffix table (LPS (Longest Prefix Suffix) array)",
      "A hash function",
      "Randomized searching",
      "A brute force approach"
    ],
    "correctIndex": 0,
    "explanation": "The KMP algorithm preprocesses the pattern to construct a 'Longest Prefix Suffix' (LPS) array (also known as the failure function). This array tells the algorithm how many characters to shift the pattern when a mismatch occurs, based on the longest proper prefix of the pattern that is also a suffix of the (matched) part of the pattern."
  },
  {
    "question": "What is the best-case time complexity of linear search?",
    "choices": [
      "O(1)",
      "O(n)",
      "O(log n)",
      "O(n2)"
    ],
    "correctIndex": 0,
    "explanation": "In the best case for linear search, the target element is found at the very first position of the array. This requires only one comparison, resulting in a constant time complexity of O(1)."
  },
  {
    "question": "Which sorting algorithm repeatedly compares and swaps adjacent elements if they are in the wrong order until the entire array is sorted?",
    "choices": [
      "Bubble Sort",
      "Quick Sort",
      "Merge Sort",
      "Selection Sort"
    ],
    "correctIndex": 0,
    "explanation": "Bubble Sort is a simple sorting algorithm that repeatedly steps through the list, compares adjacent elements and swaps them if they are in the wrong order. This process is repeated until no swaps are needed, which indicates the list is sorted."
  },
  {
    "question": "Which sorting algorithm requires O(n) additional space due to its recursive implementation?",
    "choices": [
      "Merge Sort",
      "Quick Sort",
      "Selection Sort",
      "Bubble Sort"
    ],
    "correctIndex": 0,
    "explanation": "Merge Sort is a 'divide and conquer' algorithm that works by splitting the array into two halves, recursively sorting them, and then merging the sorted halves. This merging process requires a temporary array of size O(n) to store the elements, hence its O(n) space complexity."
  },
  {
    "question": "Which sorting algorithm has an average-case time complexity of O(n²)?",
    "choices": [
      "Bubble Sort",
      "Quick Sort",
      "Merge Sort",
      "Heap Sort"
    ],
    "correctIndex": 0,
    "explanation": "Bubble Sort, along with Selection Sort and Insertion Sort, has an average-case time complexity of O(n²). This makes it inefficient for large datasets. Quick Sort, Merge Sort, and Heap Sort have a much better average time complexity of O(n log n)."
  },
  {
    "question": "Which sorting algorithm works by repeatedly dividing the list into two halves, sorting each half, and then merging them?",
    "choices": [
      "Merge Sort",
      "Quick Sort",
      "Selection Sort",
      "Insertion Sort"
    ],
    "correctIndex": 0,
    "explanation": "Merge Sort is a 'divide and conquer' algorithm. It recursively divides the array into sub-arrays until each sub-array has only one element (which is by definition sorted), then it merges the sub-arrays back together in a sorted manner."
  },
  {
    "question": "The worst-case time complexity of Quick Sort and Bubble Sort is the same, O(n²), when the input array is already sorted in ascending order or sorted in reverse order.",
    "choices": [
      "True",
      "False"
    ],
    "correctIndex": 0,
    "explanation": "True. For Bubble Sort, the worst case occurs for a reverse-sorted array. For Quick Sort, the worst-case O(n²) time complexity occurs when the pivot selection consistently results in imbalanced partitions, such as when the array is already sorted in ascending or descending order and the first or last element is chosen as the pivot."
  },
  {
    "question": "A teacher has an almost sorted list of student grades. Which algorithm provides the most time-efficient sorting?",
    "choices": [
      "Insertion Sort",
      "Bubble Sort",
      "Selection Sort",
      "Quick Sort"
    ],
    "correctIndex": 0,
    "explanation": "Insertion Sort performs exceptionally well on nearly sorted data. In its best-case scenario (an already sorted array), its time complexity is O(n), as it only needs to iterate through the list once to confirm it's sorted. For a nearly sorted array, it will perform very few swaps, making it highly efficient."
  },
  {
    "question": "Which sorting algorithm uses a divide-and-conquer approach?",
    "choices": [
      "Quick Sort",
      "Insertion Sort",
      "Bubble Sort",
      "Selection Sort"
    ],
    "correctIndex": 0,
    "explanation": "Quick Sort is a classic example of a 'divide and conquer' algorithm. It partitions an array into two sub-arrays around a pivot element, then recursively sorts the sub-arrays."
  },
  {
    "question": "True or False: Insertion Sort performs well on nearly sorted data.",
    "choices": [
      "True",
      "False"
    ],
    "correctIndex": 0,
    "explanation": "True. Insertion Sort's time complexity becomes linear, O(n), for a nearly sorted array, as it only needs to perform a minimal number of shifts and comparisons to place the few misplaced elements."
  },
  {
    "question": "In which sorting algorithm is the number of swaps directly proportional to the number of inversions in the input array?",
    "choices": [
      "Insertion Sort",
      "Quick Sort",
      "Bubble Sort",
      "Merge Sort"
    ],
    "correctIndex": 0,
    "explanation": "Insertion Sort's performance is closely tied to the number of inversions. An inversion is a pair of elements that are out of order. Each swap in Insertion Sort fixes exactly one inversion, so the number of swaps is directly proportional to the number of inversions."
  },
  {
    "question": "When sorting a nearly sorted array, which algorithm is likely to perform the best?",
    "choices": [
      "Insertion Sort",
      "Quick Sort",
      "Bubble Sort",
      "Merge Sort"
    ],
    "correctIndex": 0,
    "explanation": "Insertion Sort is highly efficient for nearly sorted data because it only performs a few comparisons and shifts to place the elements that are out of order, leading to a near-linear time complexity."
  },
  {
    "question": "When does Bubble Sort achieve its best-case time complexity of O(n)?",
    "choices": [
      "Already sorted",
      "Reverse sorted",
      "Randomly sorted",
      "Contains duplicate elements"
    ],
    "correctIndex": 0,
    "explanation": "Bubble Sort's best-case time complexity is O(n) when the array is already sorted. The algorithm will perform one full pass through the array, detect that no swaps were made, and then terminate early."
  },
  {
    "question": "Selection Sort is more efficient than Insertion Sort when dealing with nearly sorted data.",
    "choices": [
      "False",
      "True"
    ],
    "correctIndex": 0,
    "explanation": "False. Selection Sort's number of comparisons and swaps remains the same regardless of the initial order of the data. Its performance does not improve on nearly sorted data, while Insertion Sort's performance does."
  },
  {
    "question": "True or False: Merge Sort has a worst-case time complexity of O(n log n).",
    "choices": [
      "True",
      "False"
    ],
    "correctIndex": 0,
    "explanation": "True. Merge Sort's time complexity is consistently O(n log n) in all cases (best, average, and worst). This is because it always divides the array into two halves and performs the merge operation, regardless of the input data's initial order."
  },
  {
    "question": "Which sorting algorithm's time complexity is not affected by the initial order of elements?",
    "choices": [
      "Merge Sort",
      "Quick Sort",
      "Insertion Sort",
      "Bubble Sort"
    ],
    "correctIndex": 0,
    "explanation": "Merge Sort's time complexity is consistently O(n log n) for all cases, as it always performs the same number of recursive divisions and merge operations, regardless of whether the array is sorted, reverse-sorted, or random."
  },
  {
    "question": "In Selection Sort, how is the smallest element positioned correctly in each iteration?",
    "choices": [
      "By swapping it with the first unsorted element",
      "By swapping with the largest element",
      "By moving it to the end",
      "By inserting it in the middle"
    ],
    "correctIndex": 0,
    "explanation": "In each pass of Selection Sort, the algorithm finds the minimum element from the unsorted part of the array and then swaps it with the first unsorted element, thus placing it in its correct sorted position."
  },
  {
    "question": "When sorting data that is nearly sorted or has only a few elements out of place, ______ is the most efficient algorithm in terms of time complexity.",
    "choices": [
      "Insertion Sort",
      "Quick Sort",
      "Merge Sort",
      "Selection Sort"
    ],
    "correctIndex": 0,
    "explanation": "Insertion Sort excels at sorting nearly sorted data because its time complexity approaches O(n) in this scenario. It simply shifts the few out-of-place elements into their correct position with minimal work."
  },
  {
    "question": "Which sorting algorithm is considered the most suitable for external sorting?",
    "choices": [
      "Merge Sort",
      "Quick Sort",
      "Bubble Sort",
      "Insertion Sort"
    ],
    "correctIndex": 0,
    "explanation": "Merge Sort is highly suitable for external sorting, which is used for datasets too large to fit in main memory. Its linear read-and-write pattern to sequential storage devices is very efficient, unlike other algorithms that may require random access."
  },
  {
    "question": "Quick Sort has a worst-case time complexity of O(n²), but its average time complexity is O(n log n), which makes it efficient for large datasets in practice.",
    "choices": [
      "True",
      "False"
    ],
    "correctIndex": 0,
    "explanation": "True. Quick Sort's average-case performance is excellent, making it one of the fastest in-place sorting algorithms for typical datasets. The worst-case of O(n²) is rare in practice with good pivot selection strategies."
  },
  {
    "question": "A cloud service needs to sort a dataset in memory, but available RAM is very limited. Which sorting algorithm is most suitable for this scenario due to its minimal additional memory usage?",
    "choices": [
      "Quick Sort",
      "Selection Sort",
      "Merge Sort",
      "Bubble Sort"
    ],
    "correctIndex": 0,
    "explanation": "While both Quick Sort and Selection Sort are in-place, Quick Sort is generally faster. Merge Sort is not suitable due to its O(n) space complexity. Therefore, Quick Sort, with its good average-case performance and minimal memory usage, is the best choice here. Selection and Bubble Sort are generally too slow for large datasets, even with limited memory."
  },
  {
    "question": "Which sorting algorithm is the most efficient for large datasets stored on secondary storage?",
    "choices": [
      "Merge Sort",
      "Insertion Sort",
      "Quick Sort",
      "Bubble Sort"
    ],
    "correctIndex": 0,
    "explanation": "Merge Sort is the most efficient choice for external sorting (large datasets on secondary storage). Its divide-and-conquer strategy, combined with sequential access to data, minimizes the number of costly disk I/O operations."
  },
  {
    "question": "______ is a divide-and-conquer algorithm that consistently performs well on large datasets but requires additional memory proportional to the size of the input.",
    "choices": [
      "Merge Sort",
      "Bubble Sort",
      "Quick Sort",
      "Selection Sort"
    ],
    "correctIndex": 0,
    "explanation": "Merge Sort is a divide-and-conquer algorithm with a consistent O(n log n) time complexity. However, its merging step requires a temporary array of size O(n), which is a key characteristic distinguishing it from in-place algorithms like Quick Sort."
  },
  {
    "question": "Which sorting algorithm has the same time complexity in its best, worst, and average cases?",
    "choices": [
      "Selection Sort",
      "Quick Sort",
      "Insertion Sort",
      "Merge Sort"
    ],
    "correctIndex": 0,
    "explanation": "Selection Sort has a consistent time complexity of O(n²) regardless of the input data's order. It always makes the same number of comparisons and swaps in each pass to find the minimum element and place it correctly, making its performance independent of the initial state of the array."
  },
  {
    "question": "In the following scenarios, when will you use selection sort?",
    "choices": [
      "Large values need to be sorted with small keys",
      "Small values need to be sorted with large keys",
      "The input is already sorted",
      "A large file has to be sorted"
    ],
    "correctIndex": 0,
    "explanation": "Selection Sort's main advantage is that it minimizes the number of swaps. It performs at most n-1 swaps. This makes it a good choice when the cost of swapping elements is very high, such as with large objects or records, while comparisons are relatively cheap."
  },
  {
    "question": "An embedded system with limited memory needs to sort small arrays (e.g., 10–20 elements). Which sorting algorithm is most suitable from the given choices?",
    "choices": [
      "Selection Sort",
      "Merge Sort",
      "Quick Sort",
      "Bubble Sort"
    ],
    "correctIndex": 0,
    "explanation": "For small datasets, the overhead of more complex algorithms like Quick Sort or Merge Sort often outweighs the performance benefits. Simple, in-place algorithms like Selection Sort or Insertion Sort are often preferred because they are easy to implement, have low memory overhead, and are fast enough for small n."
  },
  {
    "question": "True or False: Quick Sort has an average-case time complexity of O(n log n).",
    "choices": [
      "True",
      "False"
    ],
    "correctIndex": 0,
    "explanation": "True. Quick Sort's average-case performance is O(n log n), which is highly efficient. This is a major reason why it's a popular choice for sorting in many applications, despite its O(n²) worst-case."
  },
  {
    "question": "Insertion Sort can be implemented iteratively but not recursively.",
    "choices": [
      "False",
      "True"
    ],
    "correctIndex": 0,
    "explanation": "False. While Insertion Sort is most commonly implemented iteratively, it can also be implemented recursively. A recursive implementation would involve sorting the sub-array of size n-1 and then inserting the last element into its correct position."
  },
  {
    "question": "The worst-case time complexity of Quick Sort occurs when which of the following holds TRUE?",
    "choices": [
      "The pivot element is always the smallest or largest.",
      "The array is already sorted.",
      "The middle element is always chosen as the pivot.",
      "The last element is always chosen as the pivot."
    ],
    "correctIndex": 0,
    "explanation": "The worst-case of O(n²) for Quick Sort happens when the pivot selection consistently results in one sub-array with n-1 elements and another with 0 elements. This occurs if the pivot is always the smallest or largest element in the sub-array, which can happen if the array is already sorted or reverse-sorted and the pivot is chosen as the first or last element."
  },
  {
    "question": "True or False: A sorting algorithm with a worst-case time complexity of O(n²) is generally considered less efficient than one with a worst-case time complexity of O(n log n).",
    "choices": [
      "True",
      "False"
    ],
    "correctIndex": 0,
    "explanation": "True. O(n log n) grows much more slowly than O(n²), especially for large values of n. This means an O(n log n) algorithm will be significantly faster than an O(n²) algorithm in the worst case for any reasonably large dataset."
  },
  {
    "question": "In Selection Sort, the swapping step occurs inside the inner loop for every comparison made.",
    "choices": [
      "False",
      "True"
    ],
    "correctIndex": 0,
    "explanation": "False. In Selection Sort, the inner loop iterates to find the minimum element's index. Only after the inner loop completes is a single swap performed to place the minimum element at the beginning of the unsorted portion of the array."
  },
  {
    "question": "Which statement is true regarding the space complexity of Merge Sort and Insertion Sort?",
    "choices": [
      "Merge Sort requires additional space for its operations, whereas Insertion Sort is an in-place algorithm.",
      "Merge Sort is more efficient for small datasets than Insertion Sort.",
      "Insertion Sort has a worst-case time complexity of O(n log n), while Merge Sort has O(n²).",
      "Insertion Sort is a divide-and-conquer algorithm, whereas Merge Sort is not."
    ],
    "correctIndex": 0,
    "explanation": "Merge Sort's merge operation typically requires a temporary array of size O(n), giving it a space complexity of O(n). Insertion Sort, on the other hand, only requires a constant amount of extra memory for temporary variables to perform swaps, making it an in-place algorithm with O(1) space complexity."
  },
  {
    "question": "The BFS algorithm is implemented using a _______ data structure.",
    "choices": [
      "Queue",
      "Stack",
      "Heap",
      "Linked List"
    ],
    "correctIndex": 0,
    "explanation": "BFS (Breadth-First Search) explores all neighbor nodes at the present depth prior to moving on to the nodes at the next depth level. A Queue is the ideal data structure for this, as it processes nodes in a first-in, first-out (FIFO) order."
  },
  {
    "question": "Which of the following problems can Depth First Search (DFS) help solve?",
    "choices": [
      "Detecting cycles in a graph",
      "Finding shortest paths in weighted graphs",
      "Finding the minimum spanning tree",
      "Computing strongly connected components"
    ],
    "correctIndex": 0,
    "explanation": "DFS explores as far as possible along each branch before backtracking. This makes it efficient for detecting cycles. When a back edge (an edge from a vertex to an already visited ancestor in the DFS tree) is found, it indicates a cycle."
  },
  {
    "question": "Breadth First Search (BFS) guarantees finding the shortest path in an unweighted graph.",
    "choices": [
      "True",
      "False"
    ],
    "correctIndex": 0,
    "explanation": "True. In an unweighted graph, all edges have the same weight (or are considered to have a weight of 1). BFS explores the graph layer by layer, so the first time it finds the destination node, it will have found a path with the fewest edges, which is the shortest path."
  },
  {
    "question": "What is the time complexity of checking whether an edge exists between two vertices in an adjacency matrix?",
    "choices": [
      "O(1)",
      "O(V)",
      "O(E)",
      "O(V²)"
    ],
    "correctIndex": 0,
    "explanation": "In an adjacency matrix, checking for an edge between vertices 'i' and 'j' simply involves looking up the value at `A[i][j]`. This is a direct array access operation, which has a constant time complexity of O(1)."
  },
  {
    "question": "Which data structure is used to implement Depth First Search (DFS)?",
    "choices": [
      "Stack",
      "Queue",
      "Heap",
      "Priority Queue"
    ],
    "correctIndex": 0,
    "explanation": "DFS explores a branch of the graph completely before backtracking. A Stack is the appropriate data structure for this, as it allows for a last-in, first-out (LIFO) order of processing, which naturally supports the 'go deeper' approach of DFS."
  },
  {
    "question": "Dijkstra’s algorithm is applicable to graphs with which type of edge weights?",
    "choices": [
      "Only positive edge weights",
      "Negative edge weights",
      "Both positive and negative edge weights",
      "No edge weights"
    ],
    "correctIndex": 0,
    "explanation": "Dijkstra’s algorithm works by greedily selecting the node with the minimum known distance. This greedy approach fails if negative weights exist, as a path with a greater initial weight might later become the shortest path due to a negative-weight edge. For graphs with negative weights, the Bellman-Ford algorithm should be used."
  },
  {
    "question": "In adjacency matrix representation, which element represents an edge between vertex i and j?",
    "choices": [
      "A[i][j] = 1",
      "A[i][j] = 0",
      "A[i][j] = -1",
      "A[i][j] = i + j"
    ],
    "correctIndex": 0,
    "explanation": "In a simple adjacency matrix, a value of 1 at `A[i][j]` signifies that an edge exists between vertex 'i' and vertex 'j'. A value of 0 indicates the absence of an edge."
  },
  {
    "question": "The adjacency list representation is preferred when the graph is _______. ",
    "choices": [
      "Sparse",
      "Dense",
      "Cyclic",
      "Complete"
    ],
    "correctIndex": 0,
    "explanation": "A sparse graph is one where the number of edges is much less than the maximum possible number of edges. The adjacency list representation uses space proportional to the number of vertices and edges (O(V+E)), making it much more memory-efficient than an adjacency matrix (O(V²)) for sparse graphs."
  },
  {
    "question": "Which of the following is not a limitation of Dijkstra’s algorithm?",
    "choices": [
      "Can only work with weighted graphs",
      "Cannot handle graphs with negative edge weights",
      "May be inefficient for very large graphs",
      "Does not work for disconnected graphs"
    ],
    "correctIndex": 0,
    "explanation": "While Dijkstra’s algorithm is designed for weighted graphs, this is not considered a limitation as it is its intended purpose. The other options are actual limitations: it cannot handle negative weights, and its efficiency can degrade with a naive implementation on large graphs. It can work on disconnected graphs, but will only find the shortest paths within the component of the starting node."
  },
  {
    "question": "What is the time complexity of Dijkstra’s algorithm when implemented with a priority queue (binary heap)?",
    "choices": [
      "O((V + E) log V)",
      "O(V²)",
      "O(V + E)",
      "O(V log V)"
    ],
    "correctIndex": 0,
    "explanation": "The time complexity is O((V + E) log V). The 'E' term comes from iterating through all edges, and the 'log V' term comes from the operations on the priority queue (insert and extract-min), which have a logarithmic time complexity."
  },
  {
    "question": "What is the worst-case time complexity of BFS for a graph with V vertices and E edges?",
    "choices": [
      "O(V + E)",
      "O(V)",
      "O(E)",
      "O(V²)"
    ],
    "correctIndex": 0,
    "explanation": "BFS has to visit every vertex and every edge once to ensure all reachable nodes are explored. For a graph represented with an adjacency list, the complexity is O(V + E). For an adjacency matrix, it would be O(V²)."
  },
  {
    "question": "What is a key property of the adjacency matrix of an undirected graph?",
    "choices": [
      "Symmetric",
      "Asymmetric",
      "Skewed",
      "Triangular"
    ],
    "correctIndex": 0,
    "explanation": "In an undirected graph, if there is an edge from vertex 'i' to 'j', there is also an edge from 'j' to 'i'. This means that the element `A[i][j]` will be equal to `A[j][i]` for all 'i' and 'j', making the matrix symmetric along its main diagonal."
  },
  {
    "question": "A priority queue is used in Dijkstra’s algorithm to select the node with the _______ shortest distance.",
    "choices": [
      "Minimum",
      "Maximum",
      "Average",
      "Random"
    ],
    "correctIndex": 0,
    "explanation": "Dijkstra’s algorithm uses a greedy approach. At each step, it selects the unvisited vertex with the smallest distance from the source. A min-priority queue is used to efficiently retrieve this minimum-distance vertex."
  },
  {
    "question": "What is the space complexity of an adjacency matrix for a graph with V vertices?",
    "choices": [
      "O(V²)",
      "O(1)",
      "O(V)",
      "O(V log V)"
    ],
    "correctIndex": 0,
    "explanation": "An adjacency matrix is a 2D array of size V x V, where V is the number of vertices. The space required to store this matrix is therefore proportional to V squared, or O(V²)."
  },
  {
    "question": "If a graph has V vertices and E edges, the worst-case time complexity of Dijkstra’s algorithm using an adjacency matrix is:",
    "choices": [
      "O(V²)",
      "O(V log E)",
      "O(V + E)",
      "O(VE)"
    ],
    "correctIndex": 0,
    "explanation": "When using an adjacency matrix, finding the unvisited vertex with the minimum distance takes O(V) time in each of the V iterations. This results in a total time complexity of O(V²)."
  },
  {
    "question": "Which data structure is commonly used to implement Dijkstra’s algorithm efficiently?",
    "choices": [
      "Priority Queue (Min Heap)",
      "Stack",
      "Queue",
      "Linked List"
    ],
    "correctIndex": 0,
    "explanation": "A priority queue (specifically a min-heap) is used to efficiently extract the vertex with the minimum distance from the source. This is the key to optimizing Dijkstra's algorithm from O(V²) to O((V + E) log V)."
  },
  {
    "question": "In an undirected graph, if vertex A is adjacent to vertex B, what can be inferred about their adjacency lists?",
    "choices": [
      "Both A and B have each other in their adjacency lists",
      "Only A has B in its adjacency list",
      "Only B has A in its adjacency list",
      "The adjacency list is not used"
    ],
    "correctIndex": 0,
    "explanation": "In an undirected graph, an edge from A to B is the same as an edge from B to A. Therefore, if there is a connection, B will be in A's adjacency list, and A will also be in B's adjacency list."
  },
  {
    "question": "Which data structure is commonly used to represent an adjacency list in a graph?",
    "choices": [
      "Linked List",
      "Array",
      "Stack",
      "Queue"
    ],
    "correctIndex": 0,
    "explanation": "An adjacency list is an array of lists. Each element in the array represents a vertex, and the list at that index contains the vertices adjacent to it. A linked list is a common choice for implementing these lists due to its dynamic nature."
  },
  {
    "question": "Which algorithm can be used as an alternative to Dijkstra’s algorithm for graphs with negative weights?",
    "choices": [
      "Bellman-Ford Algorithm",
      "Kruskal’s Algorithm",
      "Floyd-Warshall Algorithm",
      "Prim’s Algorithm"
    ],
    "correctIndex": 0,
    "explanation": "The Bellman-Ford algorithm can correctly find the shortest path in a graph containing negative edge weights. Unlike Dijkstra's, it can also detect negative cycles, where a path can be made infinitely shorter."
  },
  {
    "question": "What is the time complexity of DFS in an adjacency list representation?",
    "choices": [
      "O(V + E)",
      "O(V)",
      "O(V²)",
      "O(E log V)"
    ],
    "correctIndex": 0,
    "explanation": "DFS, like BFS, must visit every vertex and every edge in the worst case to explore the entire graph. With an adjacency list, the total time to visit all vertices is O(V), and the time to traverse all edges is O(E). Thus, the total complexity is O(V + E)."
  },
  {
    "question": "Which graph representation is preferred for algorithms like Dijkstra’s and Prim’s?",
    "choices": [
      "Adjacency List",
      "Adjacency Matrix",
      "Incidence Matrix",
      "Edge List"
    ],
    "correctIndex": 0,
    "explanation": "Both Dijkstra’s and Prim’s algorithms work by visiting nodes and their adjacent edges. An adjacency list provides an efficient way to iterate through all neighbors of a vertex in O(degree(V)) time, which is much faster than an O(V) scan required by an adjacency matrix, especially for sparse graphs."
  },
  {
    "question": "What is the time complexity of BFS in an adjacency list representation?",
    "choices": [
      "O(V + E)",
      "O(V)",
      "O(V²)",
      "O(E log V)"
    ],
    "correctIndex": 0,
    "explanation": "BFS requires visiting every vertex once and traversing every edge once. When using an adjacency list, which provides efficient access to a vertex's neighbors, the overall time complexity is O(V + E)."
  },
  {
    "question": "How does Dijkstra’s algorithm determine the shortest path?",
    "choices": [
      "By updating distances to neighbors using the minimum current path",
      "By exploring all paths exhaustively",
      "By using a recursive approach",
      "By using a breadth-first strategy"
    ],
    "correctIndex": 0,
    "explanation": "Dijkstra's algorithm determines the shortest path by maintaining a set of visited nodes and their minimum distances. At each step, it greedily selects the unvisited node with the smallest known distance from the source and updates the distances of all its unvisited neighbors."
  },
  {
    "question": "What is the first step in Dijkstra’s algorithm?",
    "choices": [
      "Initialize all distances to infinity except the source node",
      "Pick an arbitrary node as the source",
      "Choose the shortest edge in the graph",
      "Remove all edges with negative weights"
    ],
    "correctIndex": 0,
    "explanation": "The first step in Dijkstra’s algorithm is to set the distance of the source node to 0 and all other nodes to infinity. This establishes a baseline for the algorithm to begin its search for the shortest paths."
  },
  {
    "question": "Which algorithm guarantees finding the shortest path in an unweighted graph?",
    "choices": [
      "Breadth First Search (BFS)",
      "Depth First Search (DFS)",
      "Dijkstra’s Algorithm",
      "Bellman-Ford Algorithm"
    ],
    "correctIndex": 0,
    "explanation": "BFS explores all neighbors at a distance of k before exploring any nodes at a distance of k+1. This layer-by-layer exploration naturally guarantees that the first time a destination is reached, the path taken will have the minimum number of edges, which is the shortest path in an unweighted graph."
  },
  {
    "question": "What is the primary advantage of an adjacency list representation over an adjacency matrix?",
    "choices": [
      "Uses less space for sparse graphs",
      "Easier to implement",
      "Faster access time",
      "Uses more memory"
    ],
    "correctIndex": 0,
    "explanation": "For a sparse graph (a graph with relatively few edges), an adjacency list only stores the existing edges, resulting in a space complexity of O(V + E). An adjacency matrix, however, always requires O(V²) space regardless of the number of edges, making the adjacency list far more memory-efficient."
  },
  {
    "question": "Which type of problem does Dijkstra’s algorithm solve, and which type of graphs is it applicable to?",
    "choices": [
      "Shortest Path",
      "Minimum Spanning Tree",
      "Topological Sorting",
      "Cycle Detection"
    ],
    "correctIndex": 0,
    "explanation": "Dijkstra’s algorithm is specifically designed to solve the single-source shortest path problem in a graph, and it works correctly on graphs with non-negative edge weights."
  },
  {
    "question": "How many edges does a complete undirected graph with n vertices have?",
    "choices": [
      "n(n - 1) / 2",
      "n",
      "n²",
      "n(n + 1) / 2"
    ],
    "correctIndex": 0,
    "explanation": "In a complete undirected graph, every vertex is connected to every other vertex. Each of the 'n' vertices connects to 'n-1' other vertices. This gives n * (n-1) connections. We divide by 2 because each edge is counted twice (once for each vertex it connects), resulting in the formula n(n - 1) / 2."
  }
]


